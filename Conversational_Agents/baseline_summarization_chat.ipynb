{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XvOluiKaG0Hb"
   },
   "source": [
    "# End to End Baseline Summarisation\n",
    "\n",
    "In this notebook you will use the configured conversation profile from earlier in the lab to perform summarization of chat transcripts with redacted PII. You will need the integration ID of your conversation profile created earlier to complete this lab.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mLtMeOqgHVEc"
   },
   "source": [
    "# Installing required libraries and Authenticating GCP Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "mq2u5TNpGzHQ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "! pip install -q google-cloud-storage google-cloud-dlp google-cloud-dialogflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__IMPORTANT:__ Restart the kernel for the notebook by going to __Kernel__ and __Restart Kernel__ before moving forward. You do not need to run the first cell again after completing the package installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n6KG5mj1I-hr"
   },
   "source": [
    "## Configure Google Cloud credentials\n",
    "\n",
    "__Note:__ Replace `project-name` with your Project ID. You will need to uncomment the commented lines first if you are running this notebook in a Google Colab environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "id": "LF0QStZrHzkq",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n"
     ]
    }
   ],
   "source": [
    "PROJECT_NAME='qwiklabs-gcp-03-0231a21cdd91' \n",
    "\n",
    "!gcloud config set project $PROJECT_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zgNLnpuPLK9T"
   },
   "source": [
    "## Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "aPhHyXo0LFSw",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Dict, List\n",
    "import csv\n",
    "import glob\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from google.cloud import storage\n",
    "import google.cloud.dlp\n",
    "from google.cloud import dialogflow_v2beta1 as dialogflow\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace the value of the`CONV_PROFILE_ID` variable with the integration ID you recorded earlier.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellView": "form",
    "id": "v5gWFyL2LSIe",
    "tags": []
   },
   "outputs": [],
   "source": [
    "CONV_PROFILE_ID = \"projects/qwiklabs-gcp-03-0231a21cdd91/locations/global/conversationProfiles/8AXI6MhBQ-GIMbVFz7a94w\"\n",
    "GCS_BUCKET_URI = \"gs://summarization_integration_test_data\" \n",
    "GCS_BUCKET_NAME = GCS_BUCKET_URI.split(\"//\")[1]\n",
    "TRANSCRIPTS_INPUT_FOLDER_PREFIX = \"data\" \n",
    "SUPPORTED_FILE_FORMATS = [\"json\"]\n",
    "\n",
    "project_id = PROJECT_NAME\n",
    "location = \"global\"\n",
    "project_path = '/'.join(CONV_PROFILE_ID.split('/')[:4])\n",
    "conversation_profile_id = CONV_PROFILE_ID"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g6vdll99TXgG"
   },
   "source": [
    "# Step 1: Run PII redaction on chat transcripts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NqEYIb8eTqYg"
   },
   "source": [
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JyQA7VHUBW2C"
   },
   "source": [
    "Before summarizing transcripts, you will redact possibly sensitive information found in the transcripts. This will lower the risk of accidental data leakage.\n",
    "\n",
    "**Note**: `INFO_TYPES` should be fine-tuned to fit customer's requirements. The existing `INFO_TYPES` in the cell below is the default setting but is subject to developer's discretion. To fine-tune `INFO_TYPES`, please refer to https://cloud.google.com/dlp/docs/infotypes-reference\n",
    "\n",
    "First, instaniate a client to interact with the Data Loss Prevention (DLP) API and a function (`redact_dlp`) to redact sensitive information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "nEJ8d9aST8Cg",
    "tags": []
   },
   "outputs": [],
   "source": [
    "dlp = google.cloud.dlp_v2.DlpServiceClient()\n",
    "INFO_TYPES = [\"AGE\",\"CREDIT_CARD_NUMBER\",\"CREDIT_CARD_TRACK_NUMBER\",\"DATE\",\"DATE_OF_BIRTH\",\n",
    "           \"DOMAIN_NAME\",\"EMAIL_ADDRESS\",\"FEMALE_NAME\",\"MALE_NAME\",\"FIRST_NAME\",\"GENDER\",\n",
    "           \"GENERIC_ID\",\"IP_ADDRESS\",\"LAST_NAME\",\"LOCATION\",\"PERSON_NAME\",\"PHONE_NUMBER\",\n",
    "           \"STREET_ADDRESS\"]\n",
    "\n",
    "def redact_dlp(input_str,replacement_str=r\"[redacted]\"):\n",
    "\n",
    "    inspect_config = {\"info_types\": [{\"name\": info_type} for info_type in INFO_TYPES]}\n",
    "    deidentify_config = {\n",
    "        \"info_type_transformations\": {\n",
    "            \"transformations\": [\n",
    "                {\n",
    "                    \"primitive_transformation\": {\n",
    "                        \"replace_config\": {\n",
    "                            \"new_value\": {\"string_value\": replacement_str}\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "    item = {\"value\": input_str}\n",
    "    response = dlp.deidentify_content(\n",
    "        request={\n",
    "            \"parent\" :\"projects/{}\".format(PROJECT_NAME),\n",
    "            \"deidentify_config\": deidentify_config,\n",
    "            \"inspect_config\": inspect_config,\n",
    "            \"item\": item,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    return str(response.item.value).strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before defining a function to apply the DLP API, you define a function to parse the chat transcripts. The code following the definition of the `parse_chat_transcripts` imports the transcripts into a Pandas dataframe to make it easier to parse and apply the DLP API to the appropriate field of the transcripts. It will take a couple of minutes to parse the 150 transcripts in the Cloud Storage location being used for this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "G4AKaXJgq0FM",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conversations Processed :: 10\n",
      "Conversations Processed :: 20\n",
      "Conversations Processed :: 30\n"
     ]
    }
   ],
   "source": [
    "storage_client = storage.Client()\n",
    "\n",
    "def parse_chat_transcripts(file_name, chat_transcript):\n",
    "  result_list = []\n",
    "  conversation_entries_list = chat_transcript['entries']\n",
    "  for index, conversation_entry in enumerate(conversation_entries_list):\n",
    "    result_dict = {}\n",
    "    result_dict['conversation_id']=file_name\n",
    "    result_dict['turn_id'] = index\n",
    "    result_dict['role'] = conversation_entry['role']\n",
    "    result_dict['text'] = redact_dlp(conversation_entry['text'])\n",
    "    result_list.append(result_dict)\n",
    "  return result_list\n",
    "\n",
    "INPUT_TRANSCRIPT_FILES_GCS_PATHS = storage_client.list_blobs(GCS_BUCKET_NAME, prefix= TRANSCRIPTS_INPUT_FOLDER_PREFIX)\n",
    "index = 1\n",
    "all_transcripts = []\n",
    "_bucket = storage_client.get_bucket(GCS_BUCKET_NAME)\n",
    "\n",
    "for chat_file_name in INPUT_TRANSCRIPT_FILES_GCS_PATHS:\n",
    "  if (str(chat_file_name.name).split(\"/\")[1] != '') and (str(chat_file_name.name).split(\"/\")[1].split(\".\")[-1] in SUPPORTED_FILE_FORMATS):\n",
    "    try:\n",
    "      _blob = _bucket.blob(chat_file_name.name)\n",
    "      with _blob.open(mode='r') as f:\n",
    "        chat = json.load(f)\n",
    "      temp = parse_chat_transcripts(str(chat_file_name.name).split(\"/\")[1].split(\".\")[0], chat)\n",
    "      all_transcripts.extend(temp)\n",
    "      if index % 10 == 0:\n",
    "       print(f\"Conversations Processed :: {str(index)}\")\n",
    "      index += 1\n",
    "\n",
    "    except Exception as e:\n",
    "      #print(\"Exception Occurred for Chat: {} \\n {}\".format(chat_file_name.name, e))\n",
    "      continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "thdjQUD2rodv"
   },
   "source": [
    "Before applying the baseline summarization model, you should explore the preprocessed and redacted output from one of the conversations. Here you will convert the `all_transcripts` into a Pandas dataframe and then look at one of the conversations. Note the portions of the conversation that were redacted by the DLP API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conversation_id</th>\n",
       "      <th>turn_id</th>\n",
       "      <th>role</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>034</td>\n",
       "      <td>0</td>\n",
       "      <td>CUSTOMER</td>\n",
       "      <td>Hello, I have been trying to figure out why th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>034</td>\n",
       "      <td>1</td>\n",
       "      <td>CUSTOMER</td>\n",
       "      <td>It is not usable at this speed.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>602</th>\n",
       "      <td>034</td>\n",
       "      <td>2</td>\n",
       "      <td>AGENT</td>\n",
       "      <td>Hi I can definitely help you with that..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>603</th>\n",
       "      <td>034</td>\n",
       "      <td>3</td>\n",
       "      <td>CUSTOMER</td>\n",
       "      <td>What is the issue?.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>034</td>\n",
       "      <td>4</td>\n",
       "      <td>AGENT</td>\n",
       "      <td>There are a few things we can try together. Ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>034</td>\n",
       "      <td>5</td>\n",
       "      <td>CUSTOMER</td>\n",
       "      <td>My name is [redacted].</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>034</td>\n",
       "      <td>6</td>\n",
       "      <td>AGENT</td>\n",
       "      <td>Thank you [redacted]. Can I have you log out t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>034</td>\n",
       "      <td>7</td>\n",
       "      <td>CUSTOMER</td>\n",
       "      <td>Okay I am trying.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>034</td>\n",
       "      <td>8</td>\n",
       "      <td>CUSTOMER</td>\n",
       "      <td>Hmmm, I have not gotten it to work and it is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>034</td>\n",
       "      <td>9</td>\n",
       "      <td>AGENT</td>\n",
       "      <td>How about checking another website for me?.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>034</td>\n",
       "      <td>10</td>\n",
       "      <td>CUSTOMER</td>\n",
       "      <td>Okay I can check.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>034</td>\n",
       "      <td>11</td>\n",
       "      <td>AGENT</td>\n",
       "      <td>Any better?.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>034</td>\n",
       "      <td>12</td>\n",
       "      <td>CUSTOMER</td>\n",
       "      <td>It didn't load any faster.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>034</td>\n",
       "      <td>13</td>\n",
       "      <td>AGENT</td>\n",
       "      <td>Can you close out all other tabs and programs ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>034</td>\n",
       "      <td>14</td>\n",
       "      <td>CUSTOMER</td>\n",
       "      <td>Okay let me do that.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>034</td>\n",
       "      <td>15</td>\n",
       "      <td>AGENT</td>\n",
       "      <td>Let me know if its still slow..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>034</td>\n",
       "      <td>16</td>\n",
       "      <td>CUSTOMER</td>\n",
       "      <td>Okay that seems to have solved it.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>034</td>\n",
       "      <td>17</td>\n",
       "      <td>AGENT</td>\n",
       "      <td>Oh that is great to hear..</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>034</td>\n",
       "      <td>18</td>\n",
       "      <td>CUSTOMER</td>\n",
       "      <td>Awesome, I can order now.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>034</td>\n",
       "      <td>19</td>\n",
       "      <td>CUSTOMER</td>\n",
       "      <td>Looks good.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>034</td>\n",
       "      <td>20</td>\n",
       "      <td>AGENT</td>\n",
       "      <td>Is there anything else i can help you with?.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>034</td>\n",
       "      <td>21</td>\n",
       "      <td>CUSTOMER</td>\n",
       "      <td>That is all for now.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>034</td>\n",
       "      <td>22</td>\n",
       "      <td>AGENT</td>\n",
       "      <td>Let us know if it happens again ..</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    conversation_id  turn_id      role  \\\n",
       "600             034        0  CUSTOMER   \n",
       "601             034        1  CUSTOMER   \n",
       "602             034        2     AGENT   \n",
       "603             034        3  CUSTOMER   \n",
       "604             034        4     AGENT   \n",
       "605             034        5  CUSTOMER   \n",
       "606             034        6     AGENT   \n",
       "607             034        7  CUSTOMER   \n",
       "608             034        8  CUSTOMER   \n",
       "609             034        9     AGENT   \n",
       "610             034       10  CUSTOMER   \n",
       "611             034       11     AGENT   \n",
       "612             034       12  CUSTOMER   \n",
       "613             034       13     AGENT   \n",
       "614             034       14  CUSTOMER   \n",
       "615             034       15     AGENT   \n",
       "616             034       16  CUSTOMER   \n",
       "617             034       17     AGENT   \n",
       "618             034       18  CUSTOMER   \n",
       "619             034       19  CUSTOMER   \n",
       "620             034       20     AGENT   \n",
       "621             034       21  CUSTOMER   \n",
       "622             034       22     AGENT   \n",
       "\n",
       "                                                  text  \n",
       "600  Hello, I have been trying to figure out why th...  \n",
       "601                    It is not usable at this speed.  \n",
       "602           Hi I can definitely help you with that..  \n",
       "603                                What is the issue?.  \n",
       "604  There are a few things we can try together. Ca...  \n",
       "605                             My name is [redacted].  \n",
       "606  Thank you [redacted]. Can I have you log out t...  \n",
       "607                                  Okay I am trying.  \n",
       "608  Hmmm, I have not gotten it to work and it is s...  \n",
       "609        How about checking another website for me?.  \n",
       "610                                  Okay I can check.  \n",
       "611                                       Any better?.  \n",
       "612                         It didn't load any faster.  \n",
       "613  Can you close out all other tabs and programs ...  \n",
       "614                               Okay let me do that.  \n",
       "615                    Let me know if its still slow..  \n",
       "616                 Okay that seems to have solved it.  \n",
       "617                         Oh that is great to hear..  \n",
       "618                          Awesome, I can order now.  \n",
       "619                                        Looks good.  \n",
       "620       Is there anything else i can help you with?.  \n",
       "621                               That is all for now.  \n",
       "622                 Let us know if it happens again ..  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df = pd.DataFrame(all_transcripts)\n",
    "mask = eval_df['conversation_id']=='034' #Update to view other conversations\n",
    "eval_df[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      001\n",
       "1      001\n",
       "2      001\n",
       "3      001\n",
       "4      001\n",
       "      ... \n",
       "618    034\n",
       "619    034\n",
       "620    034\n",
       "621    034\n",
       "622    034\n",
       "Name: conversation_id, Length: 623, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_df['conversation_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c2j9vBCnXK17"
   },
   "source": [
    "# Step 2: Generate summaries from Baseline Summarization Model\n",
    "\n",
    "In this step you will generate summaries for the redacted transcripts from the previous steps after defining a sequence of helper functions to work through the appropriate steps. The comments in the code give a rough description of each of the helper functions being created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "-BOSlFllaV2J",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to create a conversation for a given conservation profile\n",
    "\n",
    "def create_conversation(client: dialogflow.ConversationsClient, project_id: str,\n",
    "                        conversation_profile_id: str):\n",
    "\n",
    "  conversation = dialogflow.Conversation()\n",
    "  conversation.conversation_profile = conversation_profile_id\n",
    "\n",
    "  request = dialogflow.CreateConversationRequest(\n",
    "      parent=project_id,\n",
    "      conversation=conversation,\n",
    "  )\n",
    "  response = client.create_conversation(request=request)\n",
    "  return response\n",
    "\n",
    "# Function to create a participant for a conversation (with a given conversation_id) with a specific role\n",
    "\n",
    "def create_participant(client: dialogflow.ParticipantsClient, conversation_id,\n",
    "                       role: dialogflow.Participant.Role):\n",
    "\n",
    "  request = dialogflow.CreateParticipantRequest(\n",
    "      parent=conversation_id,\n",
    "      participant=dialogflow.Participant(role=role),\n",
    "  )\n",
    "  response = client.create_participant(request=request)\n",
    "\n",
    "  return response\n",
    "\n",
    "# Function to suggest a conversation summary using the configured conversation profile.\n",
    "\n",
    "def suggest_conversation_summary(client: dialogflow.ConversationsClient,\n",
    "                                 conversation_id: str):\n",
    "\n",
    "  request = dialogflow.SuggestConversationSummaryRequest(\n",
    "      conversation=conversation_id,)\n",
    "  response = client.suggest_conversation_summary(request=request)\n",
    "\n",
    "  return response\n",
    "\n",
    "# Function to complete a conversation with a given conversation id.\n",
    "\n",
    "def complete_conversation(client: dialogflow.ConversationsClient,\n",
    "                          conversation_id: str):\n",
    "\n",
    "  request = dialogflow.CompleteConversationRequest(name=conversation_id,)\n",
    "  response = client.complete_conversation(request)\n",
    "\n",
    "  return response\n",
    "\n",
    "# Function to return a summary for a conversation using a specific conversation profile\n",
    "# using the earlier helper functions.\n",
    "\n",
    "def get_summary(\n",
    "    conversations_client: dialogflow.ConversationsClient,\n",
    "    participants_client: dialogflow.ParticipantsClient,\n",
    "    project_id: str,\n",
    "    conversation_profile_id: str,\n",
    "    conversation,\n",
    "):\n",
    "\n",
    "  create_conversation_response = create_conversation(\n",
    "      client=conversations_client,\n",
    "      project_id=project_id,\n",
    "      conversation_profile_id=conversation_profile_id,\n",
    "  )\n",
    "  conversation_id = create_conversation_response.name\n",
    "\n",
    "  create_end_user_participant_response = create_participant(\n",
    "      client=participants_client,\n",
    "      conversation_id=conversation_id,\n",
    "      role=dialogflow.Participant.Role.END_USER,\n",
    "  )\n",
    "  end_user_participant_id = create_end_user_participant_response.name\n",
    "\n",
    "  create_human_agent_participant_response = create_participant(\n",
    "      client=participants_client,\n",
    "      conversation_id=conversation_id,\n",
    "      role=dialogflow.Participant.Role.HUMAN_AGENT,\n",
    "  )\n",
    "  human_agent_participant_id = create_human_agent_participant_response.name\n",
    "\n",
    "  batch_request = dialogflow.BatchCreateMessagesRequest()\n",
    "  batch_request.parent = conversation_id\n",
    "  turn_count = 0\n",
    "  for role, text in conversation:\n",
    "    if turn_count > 199: # API was erroring out if the conv length is more than 200\n",
    "      # Pushing first 200 messages into the conversation\n",
    "      batch_response = conversations_client.batch_create_messages(request=batch_request)\n",
    "\n",
    "      # re-initiatizing batch request to continue updating messages\n",
    "      batch_request = dialogflow.BatchCreateMessagesRequest()\n",
    "      batch_request.parent = conversation_id\n",
    "\n",
    "      turn_count = 0\n",
    "\n",
    "    participant_id = human_agent_participant_id if role == 'AGENT' else end_user_participant_id\n",
    "\n",
    "    #Batch creating Conversation\n",
    "    requests = dialogflow.CreateMessageRequest()\n",
    "    requests.parent = conversation_id\n",
    "    requests.message.content = text\n",
    "    requests.message.participant = participant_id\n",
    "    requests.message.send_time = datetime.datetime.now()\n",
    "\n",
    "    batch_request.requests.append(requests)\n",
    "    turn_count += 1\n",
    "\n",
    "  batch_create_message_response = conversations_client.batch_create_messages(request=batch_request)\n",
    "  suggest_conversation_summary_response = suggest_conversation_summary(\n",
    "      client=conversations_client,\n",
    "      conversation_id=conversation_id,\n",
    "  )\n",
    "\n",
    "  return suggest_conversation_summary_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VHOXewKXs6KZ"
   },
   "source": [
    "Now call the Summarization API for transcript summarization to add the summary to the conversation strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "UG8Qi6zicZr2",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 conversations have been summarized\n",
      "20 conversations have been summarized\n",
      "30 conversations have been summarized\n"
     ]
    }
   ],
   "source": [
    "conversations_client = dialogflow.ConversationsClient()\n",
    "participants_client = dialogflow.ParticipantsClient()\n",
    "results = []\n",
    "\n",
    "for conversation_id in eval_df['conversation_id'].unique():\n",
    "\n",
    "  #print(f'Running inference for: {conversation_id}')\n",
    "  \n",
    "  conversation = []\n",
    "  conversation_df = eval_df.loc[(eval_df['conversation_id'] == conversation_id)]\n",
    "\n",
    "  for idx in conversation_df.index:\n",
    "\n",
    "    conversation.append((conversation_df.loc[idx, 'role'], conversation_df.loc[idx, 'text']))\n",
    "\n",
    "  get_summary_response = get_summary(\n",
    "      conversations_client=conversations_client,\n",
    "      participants_client=participants_client,\n",
    "      project_id=project_path,\n",
    "      conversation_profile_id=conversation_profile_id,\n",
    "      conversation=conversation,\n",
    "  )\n",
    "\n",
    "  conversation_string = '\\n'.join(\n",
    "      (f'{role}: {text}' for role, text in conversation))\n",
    "  results.append({\n",
    "      'transcript_id': conversation_id,\n",
    "      'full_conversation': conversation_string,\n",
    "      'summary': get_summary_response.summary.text\n",
    "  })\n",
    "\n",
    "  if int(conversation_id) % 10 == 0:\n",
    "    print(f'{int(conversation_id)} conversations have been summarized')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hlmNZLofrzeA"
   },
   "source": [
    "Now we can explore the output from the baseline summarization model for the conversation (`034`) that you looked at earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('situation\\n'\n",
      " 'Customer reports that the website is slow.\\n'\n",
      " 'action\\n'\n",
      " 'Agent asks the customer to log out and back in, check another website, and '\n",
      " 'close out all other tabs and programs.\\n'\n",
      " 'resolution\\n'\n",
      " 'Yes')\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "\n",
    "summ_df = pd.DataFrame(results)\n",
    "mask = summ_df['transcript_id']=='034'\n",
    "pprint.pprint(summ_df[mask].iloc[0]['summary'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m130",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m130"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
