{
  "cells": [
    {
      "cell_type": "code",
      "id": "gaFLmzN34E1v7uG34NiyTNyX",
      "metadata": {
        "tags": [],
        "id": "gaFLmzN34E1v7uG34NiyTNyX"
      },
      "source": [
        "%pip install --upgrade --quiet google-genai nest-asyncio==1.5.9"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from inspect import cleandoc\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "import vertexai\n",
        "from vertexai.generative_models import GenerativeModel, GenerationConfig\n",
        "from vertexai.evaluation import (\n",
        "    MetricPromptTemplateExamples,\n",
        "    EvalTask,\n",
        "    PairwiseMetric,\n",
        "    PairwiseMetricPromptTemplate,\n",
        "    PointwiseMetric,\n",
        "    PointwiseMetricPromptTemplate,\n",
        ")\n",
        "\n",
        "pd.set_option(\"display.max_colwidth\", None)"
      ],
      "metadata": {
        "id": "1Jnpsidlc6mt"
      },
      "id": "1Jnpsidlc6mt",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TBD: In a new code block, initialize Gen AI with vertexai.init(). Use the us-west1 location and run the cell.\n",
        "PROJECT_ID = \"qwiklabs-gcp-03-d6b4e0cf43df\"\n",
        "LOCATION = \"us-central1\"\n",
        "import vertexai\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)"
      ],
      "metadata": {
        "id": "jf3-ISPPdLjQ"
      },
      "id": "jf3-ISPPdLjQ",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 2. Explore example data and generate a document\n",
        "\n",
        "In this task, you will set up some sample data for a film production including crew rates, shooting schedules and then define questions for a large language model to answer.\n",
        "\n",
        "1. Run the following code in a new cell to instantiate some example data. The calls to cleandoc() helps remove the indents and extra lines used for making the multi-line string readable in the code."
      ],
      "metadata": {
        "id": "AnrW7lCXdvo3"
      },
      "id": "AnrW7lCXdvo3"
    },
    {
      "cell_type": "code",
      "source": [
        "hourly_rates = cleandoc(\"\"\"\n",
        "  Screenwriter: $40\n",
        "  Actor: $25\n",
        "  Director: $30\n",
        "  Camera Operator: $35\n",
        "  Sound Engineer: $20\n",
        "  Editor: $30\n",
        "  \"\"\")\n",
        "\n",
        "planning_notes = cleandoc(\"\"\"\n",
        " Phases of Production:\n",
        "   Writing:\n",
        "   The Screenwriter will write the script.\n",
        "   They need 72 hours to do so.\n",
        "\n",
        "\n",
        "   Pre-Production:\n",
        "   The Director needs time to analyze the script.\n",
        "   They will work on it for 36 hours.\n",
        "   The Camera Operator will join the director for 24 hours of planning.\n",
        "\n",
        "\n",
        "   Production Phase 1\n",
        "   The first three days of filming will require the director, 4 actors, the camera operator, and the sound engineer\n",
        "\n",
        "\n",
        "   Production Phase 2\n",
        "   The next three days of filming will require the director, 8 actors, the camera operator, and the sound engineer\n",
        "\n",
        "\n",
        "   Post-Production\n",
        "   The editor will take 64 hours to edit the film.\n",
        "   The director will work with the editor for 24 hours during this phase.\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "8kK-Euh7dWmm"
      },
      "id": "8kK-Euh7dWmm",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tasks = [\n",
        "    \"\"\"What is the cost of each phase of production?\n",
        "    If days are mentioned, assume an 8 hour work day.\"\"\",\n",
        "\n",
        "    \"\"\"How many days will each phase require? Assume an\n",
        "    8 hour work day. If multiple people are working in parallel,\n",
        "    do not add those times together, but only use the longest time.\n",
        "    Also include a count of the total number of days of the entire\n",
        "    project.\"\"\",\n",
        "\n",
        "    \"\"\"Prepare a text schedule for all phases of the film starting\n",
        "    on Feb 3, 2025. The whole crew should be off Saturdays\n",
        "    and Sundays.\"\"\"\n",
        "]"
      ],
      "metadata": {
        "id": "ystEEOwLd8GZ"
      },
      "id": "ystEEOwLd8GZ",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = cleandoc(\"\"\"\n",
        "  <instructions>\n",
        "  Prepare a document to fulfill the task based on the context provided.\n",
        "  </instructions>\n",
        "<task>\n",
        "  {task}\n",
        "  </task>\n",
        "<context>\n",
        "  {context}\n",
        "  </context>\n",
        "  \"\"\")"
      ],
      "metadata": {
        "id": "K5jzv4A7eH1F"
      },
      "id": "K5jzv4A7eH1F",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_pro = GenerativeModel(\n",
        "  \"gemini-2.5-pro\",\n",
        "  generation_config={\n",
        "      \"temperature\": 0,\n",
        "      \"top_p\": 0.4,\n",
        "  },\n",
        ")\n",
        "\n",
        "llm_flash = GenerativeModel(\n",
        "  \"gemini-2.0-flash-001\",\n",
        "  generation_config={\n",
        "      \"temperature\": 0,\n",
        "      \"top_p\": 0.4,\n",
        "  },\n",
        ")"
      ],
      "metadata": {
        "id": "IfOcHSa4eJf9"
      },
      "id": "IfOcHSa4eJf9",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context = hourly_rates + \"\\n\\n\" + planning_notes\n",
        "prompt = prompt_template.format(context=context, task=str(tasks[1]))"
      ],
      "metadata": {
        "id": "KPlwqs-QeY21"
      },
      "id": "KPlwqs-QeY21",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check results for \"llm_pro\" model:\n",
        "Markdown(llm_pro.generate_content(prompt).text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "pRe4ozBHeh20",
        "outputId": "2a333bdc-1f07-4072-ba05-2345354d4af8"
      },
      "id": "pRe4ozBHeh20",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Based on the context provided, here is the breakdown of the number of days required for each phase and the total for the project.\n\nAll calculations assume an 8-hour workday. For parallel work, the longest duration is used.\n\n### **Phase Durations**\n\n*   **Writing:**\n    The Screenwriter requires 72 hours.\n    *Calculation: 72 hours / 8 hours per day = 9 days*\n    **Days Required: 9**\n\n*   **Pre-Production:**\n    The Director requires 36 hours and the Camera Operator requires 24 hours. As this work is done in parallel, the longest time is used.\n    *Calculation: 36 hours / 8 hours per day = 4.5 days*\n    **Days Required: 4.5**\n\n*   **Production Phase 1:**\n    The duration for this phase is explicitly stated.\n    **Days Required: 3**\n\n*   **Production Phase 2:**\n    The duration for this phase is explicitly stated.\n    **Days Required: 3**\n\n*   **Post-Production:**\n    The Editor requires 64 hours and the Director requires 24 hours. As this work is done in parallel, the longest time is used.\n    *Calculation: 64 hours / 8 hours per day = 8 days*\n    **Days Required: 8**\n\n---\n\n### **Total Project Duration**\n\nThe total number of days for the project is the sum of all phases.\n\n*   **Writing:** 9 days\n*   **Pre-Production:** 4.5 days\n*   **Production Phase 1:** 3 days\n*   **Production Phase 2:** 3 days\n*   **Post-Production:** 8 days\n\n**Total Project Days: 27.5**"
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check results for \"llm_flash\" model:\n",
        "# Markdown(llm_flash.generate_content(context + \"\\n\\n\" + str(tasks[1])).text)\n",
        "Markdown(llm_flash.generate_content(prompt).text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "9r-x0xGLgHzP",
        "outputId": "842658ae-107f-4781-ada1-d9bd8f70830c"
      },
      "id": "9r-x0xGLgHzP",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**Project Timeline Breakdown**\n\nHere's a breakdown of the project timeline, assuming an 8-hour workday:\n\n**Phase Breakdown:**\n\n*   **Writing:**\n    *   Screenwriter: 72 hours\n    *   Days Required: 72 hours / 8 hours/day = 9 days\n\n*   **Pre-Production:**\n    *   Director: 36 hours\n    *   Camera Operator: 24 hours\n    *   Since the director and camera operator are working in parallel, we take the longest time.\n    *   Days Required: 36 hours / 8 hours/day = 4.5 days\n\n*   **Production Phase 1:**\n    *   Director, 4 Actors, Camera Operator, Sound Engineer: 3 days\n    *   Days Required: 3 days\n\n*   **Production Phase 2:**\n    *   Director, 8 Actors, Camera Operator, Sound Engineer: 3 days\n    *   Days Required: 3 days\n\n*   **Post-Production:**\n    *   Editor: 64 hours\n    *   Director: 24 hours\n    *   Since the editor and director are working in parallel, we take the longest time.\n    *   Days Required: 64 hours / 8 hours/day = 8 days\n\n**Total Project Days:**\n\n9 days (Writing) + 4.5 days (Pre-Production) + 3 days (Production Phase 1) + 3 days (Production Phase 2) + 8 days (Post-Production) = **27.5 days**\n"
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yCJLnNbhi5rm"
      },
      "id": "yCJLnNbhi5rm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 3. Prepare the Evaluation Dataset and EvalTask\n",
        "In this task, you will set up the data and scoring method to evaluate the models.\n",
        "\n",
        "1. You will evaluate the models' responses against each other by using Pairwise question answering quality. Note the user input fields in curly braces in this prompt, which are required to evaluate this metrics. You will use the Gemini Pro responses as your **baseline model response** and your Gemini Flash responses as your **responses**.\n",
        "\n",
        "2. Prepare a Pandas DataFrame with the fields needed for evaluation."
      ],
      "metadata": {
        "id": "VKjULzoOjLWc"
      },
      "id": "VKjULzoOjLWc"
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt = prompt_template.format(context=context, task=str(tasks[1]))\n",
        "# full_prompts = [context + str(task) for task in tasks]\n",
        "\n",
        "# prompt_template.format(context=context, task=str(tasks[1]))\n",
        "\n",
        "full_prompts = pd.DataFrame({\n",
        "    \"context\": [context, context, context],\n",
        "    \"task\": [str(tasks[0]), str(tasks[1]), str(tasks[2])]\n",
        "})\n",
        "\n",
        "print(len(full_prompts))\n",
        "# print(full_prompts[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3FxyI_v3piWX",
        "outputId": "f2ddb781-aa19-4f9a-b6b3-504603e32616"
      },
      "id": "3FxyI_v3piWX",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming you have a dataset loaded into a pandas DataFrame.\n",
        "# The dataset should contain columns relevant to the pairwise evaluation,\n",
        "# such as 'prompt', 'response', and 'baseline_model_response'.\n",
        "\n",
        "# eval_dataset = pd.DataFrame({\n",
        "#     \"prompt\": [\"What is the capital of France?\", \"Who wrote 'Romeo and Juliet'?\", \"What is the formula for water?\"],\n",
        "#     \"response\": [\"Paris is the capital of France.\", \"William Shakespeare wrote 'Romeo and Juliet'.\", \"The formula for water is H2O.\"],\n",
        "#     \"baseline_model_response\": [\"France's capital is Paris.\", \"'Romeo and Juliet' was written by Shakespeare.\", \"Water's chemical formula is H2O.\"]\n",
        "# })\n",
        "\n",
        "\n",
        "eval_dataset = pd.DataFrame({\n",
        "    \"context\": [context, context, context],\n",
        "    \"task\": [str(tasks[0]), str(tasks[1]), str(tasks[2])]\n",
        "})\n",
        "\n",
        "# Create the EvalTask with the dataset and the specified pairwise metric.\n",
        "eval_task = EvalTask(\n",
        "    dataset=eval_dataset,\n",
        "    metrics=[\n",
        "        MetricPromptTemplateExamples.Pairwise.QUESTION_ANSWERING_QUALITY\n",
        "    ],\n",
        "    experiment=\"indie-film-planning\",\n",
        ")"
      ],
      "metadata": {
        "id": "trhJjMAEjMnV"
      },
      "id": "trhJjMAEjMnV",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "grm58L1vn1Wk"
      },
      "id": "grm58L1vn1Wk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 4. Run the evaluations and examine results\n",
        "In this task, you will ask a model to choose a preferred response for each task from the two large language models llm_pro and llm_flash.\n",
        "\n",
        "1. Run the evaluation of the EvalTask you configured above.\n",
        "\n",
        "**Note:** This may take 2 minutes to run.\n",
        "\n",
        "2. Print the summary_table of the evaluation results.\n",
        "\n",
        "3. Display the evaluation response's metrics_table. Do you see a clear preference for either model, according to the evaluation service?\n",
        "\n",
        "4. To simplify reading the results, display the column from the metrics_table that includes the evaluation service's preferred response for this example.\n",
        "\n",
        "5. Next, display the column from the metrics_table that contains the model's explanations of its choices. Read some of the results to understand the evaluation service's preferences."
      ],
      "metadata": {
        "id": "VeKyP2Xon1wp"
      },
      "id": "VeKyP2Xon1wp"
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "\n",
        "run_ts = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "\n",
        "# run the evaluation for model 'llm_pro' using eval_task.evaluate()\n",
        "eval_result = eval_task.evaluate(\n",
        "    model=llm_pro,\n",
        "    prompt_template=prompt_template,\n",
        "    experiment_run_name=f\"indie-film-planning-{run_ts}\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "id": "WMdNbfpBmgtF",
        "outputId": "c5bd0f64-b2df-43b7-8411-c7125fa027ba"
      },
      "id": "WMdNbfpBmgtF",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        \n",
              "    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons\">\n",
              "    <style>\n",
              "      .view-vertex-resource,\n",
              "      .view-vertex-resource:hover,\n",
              "      .view-vertex-resource:visited {\n",
              "        position: relative;\n",
              "        display: inline-flex;\n",
              "        flex-direction: row;\n",
              "        height: 32px;\n",
              "        padding: 0 12px;\n",
              "          margin: 4px 18px;\n",
              "        gap: 4px;\n",
              "        border-radius: 4px;\n",
              "\n",
              "        align-items: center;\n",
              "        justify-content: center;\n",
              "        background-color: rgb(255, 255, 255);\n",
              "        color: rgb(51, 103, 214);\n",
              "\n",
              "        font-family: Roboto,\"Helvetica Neue\",sans-serif;\n",
              "        font-size: 13px;\n",
              "        font-weight: 500;\n",
              "        text-transform: uppercase;\n",
              "        text-decoration: none !important;\n",
              "\n",
              "        transition: box-shadow 280ms cubic-bezier(0.4, 0, 0.2, 1) 0s;\n",
              "        box-shadow: 0px 3px 1px -2px rgba(0,0,0,0.2), 0px 2px 2px 0px rgba(0,0,0,0.14), 0px 1px 5px 0px rgba(0,0,0,0.12);\n",
              "      }\n",
              "      .view-vertex-resource:active {\n",
              "        box-shadow: 0px 5px 5px -3px rgba(0,0,0,0.2),0px 8px 10px 1px rgba(0,0,0,0.14),0px 3px 14px 2px rgba(0,0,0,0.12);\n",
              "      }\n",
              "      .view-vertex-resource:active .view-vertex-ripple::before {\n",
              "        position: absolute;\n",
              "        top: 0;\n",
              "        bottom: 0;\n",
              "        left: 0;\n",
              "        right: 0;\n",
              "        border-radius: 4px;\n",
              "        pointer-events: none;\n",
              "\n",
              "        content: '';\n",
              "        background-color: rgb(51, 103, 214);\n",
              "        opacity: 0.12;\n",
              "      }\n",
              "      .view-vertex-icon {\n",
              "        font-size: 18px;\n",
              "      }\n",
              "    </style>\n",
              "  \n",
              "        <a class=\"view-vertex-resource\" id=\"view-vertex-resource-cfe19362-9b3c-47a8-9e6a-27ea2c93e779\" href=\"#view-view-vertex-resource-cfe19362-9b3c-47a8-9e6a-27ea2c93e779\">\n",
              "          <span class=\"material-icons view-vertex-icon\">science</span>\n",
              "          <span>View Experiment</span>\n",
              "        </a>\n",
              "        \n",
              "        <script>\n",
              "          (function () {\n",
              "            const link = document.getElementById('view-vertex-resource-cfe19362-9b3c-47a8-9e6a-27ea2c93e779');\n",
              "            link.addEventListener('click', (e) => {\n",
              "              if (window.google?.colab?.openUrl) {\n",
              "                window.google.colab.openUrl('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/indie-film-planning/runs?project=qwiklabs-gcp-03-d6b4e0cf43df');\n",
              "              } else {\n",
              "                window.open('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/indie-film-planning/runs?project=qwiklabs-gcp-03-d6b4e0cf43df', '_blank');\n",
              "              }\n",
              "              e.stopPropagation();\n",
              "              e.preventDefault();\n",
              "            });\n",
              "          })();\n",
              "        </script>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "        \n",
              "    <link rel=\"stylesheet\" href=\"https://fonts.googleapis.com/icon?family=Material+Icons\">\n",
              "    <style>\n",
              "      .view-vertex-resource,\n",
              "      .view-vertex-resource:hover,\n",
              "      .view-vertex-resource:visited {\n",
              "        position: relative;\n",
              "        display: inline-flex;\n",
              "        flex-direction: row;\n",
              "        height: 32px;\n",
              "        padding: 0 12px;\n",
              "          margin: 4px 18px;\n",
              "        gap: 4px;\n",
              "        border-radius: 4px;\n",
              "\n",
              "        align-items: center;\n",
              "        justify-content: center;\n",
              "        background-color: rgb(255, 255, 255);\n",
              "        color: rgb(51, 103, 214);\n",
              "\n",
              "        font-family: Roboto,\"Helvetica Neue\",sans-serif;\n",
              "        font-size: 13px;\n",
              "        font-weight: 500;\n",
              "        text-transform: uppercase;\n",
              "        text-decoration: none !important;\n",
              "\n",
              "        transition: box-shadow 280ms cubic-bezier(0.4, 0, 0.2, 1) 0s;\n",
              "        box-shadow: 0px 3px 1px -2px rgba(0,0,0,0.2), 0px 2px 2px 0px rgba(0,0,0,0.14), 0px 1px 5px 0px rgba(0,0,0,0.12);\n",
              "      }\n",
              "      .view-vertex-resource:active {\n",
              "        box-shadow: 0px 5px 5px -3px rgba(0,0,0,0.2),0px 8px 10px 1px rgba(0,0,0,0.14),0px 3px 14px 2px rgba(0,0,0,0.12);\n",
              "      }\n",
              "      .view-vertex-resource:active .view-vertex-ripple::before {\n",
              "        position: absolute;\n",
              "        top: 0;\n",
              "        bottom: 0;\n",
              "        left: 0;\n",
              "        right: 0;\n",
              "        border-radius: 4px;\n",
              "        pointer-events: none;\n",
              "\n",
              "        content: '';\n",
              "        background-color: rgb(51, 103, 214);\n",
              "        opacity: 0.12;\n",
              "      }\n",
              "      .view-vertex-icon {\n",
              "        font-size: 18px;\n",
              "      }\n",
              "    </style>\n",
              "  \n",
              "        <a class=\"view-vertex-resource\" id=\"view-vertex-resource-9fa8f857-2b20-4d6d-ba14-47e8e4d72faf\" href=\"#view-view-vertex-resource-9fa8f857-2b20-4d6d-ba14-47e8e4d72faf\">\n",
              "          <span class=\"material-icons view-vertex-icon\">science</span>\n",
              "          <span>View Experiment Run</span>\n",
              "        </a>\n",
              "        \n",
              "        <script>\n",
              "          (function () {\n",
              "            const link = document.getElementById('view-vertex-resource-9fa8f857-2b20-4d6d-ba14-47e8e4d72faf');\n",
              "            link.addEventListener('click', (e) => {\n",
              "              if (window.google?.colab?.openUrl) {\n",
              "                window.google.colab.openUrl('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/indie-film-planning/runs/indie-film-planning-indie-film-planning-20250627-044926?project=qwiklabs-gcp-03-d6b4e0cf43df');\n",
              "              } else {\n",
              "                window.open('https://console.cloud.google.com/vertex-ai/experiments/locations/us-central1/experiments/indie-film-planning/runs/indie-film-planning-indie-film-planning-20250627-044926?project=qwiklabs-gcp-03-d6b4e0cf43df', '_blank');\n",
              "              }\n",
              "              e.stopPropagation();\n",
              "              e.preventDefault();\n",
              "            });\n",
              "          })();\n",
              "        </script>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:vertexai.evaluation.eval_task:Logging Eval Experiment metadata: {'prompt_template': '  <instructions>\\n  Prepare a document to fulfill the task based on the context provided.\\n  </instructions>\\n<task>\\n  {task}\\n  </task>\\n<context>\\n  {context}\\n  </context>\\n  ', 'model_name': 'publishers/google/models/gemini-2.5-pro', 'temperature': 0, 'top_p': 0.4}\n",
            "INFO:vertexai.evaluation._evaluation:Assembling prompts from the `prompt_template`. The `prompt` column in the `EvalResult.metrics_table` has the assembled prompts used for model response generation.\n",
            "INFO:vertexai.evaluation._evaluation:Generating a total of 3 responses from Gemini model gemini-2.5-pro.\n",
            "100%|██████████| 3/3 [00:23<00:00,  7.81s/it]\n",
            "INFO:vertexai.evaluation._evaluation:All 3 responses are successfully generated from Gemini model gemini-2.5-pro.\n",
            "INFO:vertexai.evaluation._evaluation:Multithreaded Batch Inference took: 23.449814522999986 seconds.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Cannot find the `baseline_model_response` column in the evaluation dataset to fill the metric prompt template for `pairwise_question_answering_quality` metric. Please check if the column is present in the evaluation dataset, or provide a key-value pair in `metric_column_mapping` parameter of `EvalTask` to map it to a different column name. The evaluation dataset columns are ['context', 'task', 'prompt', 'response'].",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-1239259248>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# run the evaluation for model 'llm_pro' using eval_task.evaluate()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m eval_result = eval_task.evaluate(\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mllm_pro\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprompt_template\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprompt_template\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/vertexai/evaluation/eval_task.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, model, prompt_template, experiment_run_name, response_column_name, baseline_model_response_column_name, evaluation_service_qps, retry_timeout, output_file_name)\u001b[0m\n\u001b[1;32m    441\u001b[0m                 \u001b[0mexperiment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experiment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbacking_tensorboard\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m             )\n\u001b[0;32m--> 443\u001b[0;31m             eval_result = self._evaluate_with_experiment(\n\u001b[0m\u001b[1;32m    444\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m                 \u001b[0mprompt_template\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprompt_template\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/vertexai/evaluation/eval_task.py\u001b[0m in \u001b[0;36m_evaluate_with_experiment\u001b[0;34m(self, model, prompt_template, experiment_run_name, evaluation_service_qps, retry_timeout, output_file_name)\u001b[0m\n\u001b[1;32m    355\u001b[0m                 \u001b[0moutput_file_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_file_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m             )\n\u001b[0;32m--> 357\u001b[0;31m             eval_result = _evaluation.evaluate(\n\u001b[0m\u001b[1;32m    358\u001b[0m                 \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m                 \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/vertexai/evaluation/_evaluation.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(dataset, metrics, model, prompt_template, metric_column_mapping, evaluation_service_qps, retry_timeout)\u001b[0m\n\u001b[1;32m    972\u001b[0m         )\n\u001b[1;32m    973\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 974\u001b[0;31m     \u001b[0m_validate_metric_column_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluation_run_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    975\u001b[0m     \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m     \u001b[0mevaluation_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_compute_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluation_run_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/vertexai/evaluation/_evaluation.py\u001b[0m in \u001b[0;36m_validate_metric_column_map\u001b[0;34m(evaluation_run_config)\u001b[0m\n\u001b[1;32m    113\u001b[0m                     \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mevaluation_run_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m                 ):\n\u001b[0;32m--> 115\u001b[0;31m                     raise ValueError(\n\u001b[0m\u001b[1;32m    116\u001b[0m                         \u001b[0;34mf\"Cannot find the `{variable}` column in the evaluation\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                         \u001b[0;34m\" dataset to fill the metric prompt template for\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Cannot find the `baseline_model_response` column in the evaluation dataset to fill the metric prompt template for `pairwise_question_answering_quality` metric. Please check if the column is present in the evaluation dataset, or provide a key-value pair in `metric_column_mapping` parameter of `EvalTask` to map it to a different column name. The evaluation dataset columns are ['context', 'task', 'prompt', 'response']."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# run the evaluation for model 'llm_flash' using eval_task.evaluate()\n",
        "eval_result = eval_task.evaluate(\n",
        "    model=llm_flash,\n",
        "    prompt_template=prompt_template,\n",
        "    experiment_run_name=f\"indie-film-planning-{run_ts}\"\n",
        ")"
      ],
      "metadata": {
        "id": "TggMwsJsnD1X"
      },
      "id": "TggMwsJsnD1X",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "name": "student-01-46f0e6e11c38 (Jun 26, 2025, 8:33:41 PM)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}