{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Deploy a RAG application with vector search in Firestore: Challenge Lab\n",
        "## GENAI069\n",
        "\n",
        "link: https://partner.cloudskillsboost.google/paths/2310/course_templates/1289/labs/531796\n",
        "\n",
        "## Objective\n",
        "This lab tests your ability to develop a real-world Generative AI Q&A solution using a RAG framework. You will use Firestore as a vector database and deploy a Flask app as a user interface to query a food safety knowledge base.\n",
        "\n",
        "This lab uses the following technologies and Google Cloud services:\n",
        " - Vertex AI\n",
        " - Vertex AI Colab Enterprise\n",
        " - Vertex AI Embeddings API\n",
        " - Gemini 2.0 Flash\n",
        " - Cloud Firestore\n",
        "\n",
        "In this challenge lab, you will demonstrate your ability to load a text document and split it into chunks, generate embeddings for each chunk, store the text chunks and their embeddings, conduct vector search to return similar documents to a query document, complete a RAG framework by having Gemini generate a response based on a context of similar documents to a query.\n",
        "\n",
        "## Task 1. Create a Colab Enterprise Notebook\n",
        "In this section, you will set up a Colab Enterprise notebook environment in the Google Cloud Console.\n",
        "\n",
        "1. In the Google Cloud Console, navigate to Vertex AI > Colab Enterprise.\n",
        "\n",
        "2. When prompted to enable APIs, click ENABLE.\n",
        "\n",
        "3. Within the Colab Enterprise panel in the console, click on Create Notebook. Rename the notebook to cymbal_ingest_to_vector_database.ipynb.\n",
        "\n",
        "4. Paste the following code into the top cell of the notebook and run the cell."
      ],
      "metadata": {
        "id": "kJDW_qverP1y"
      },
      "id": "kJDW_qverP1y"
    },
    {
      "cell_type": "code",
      "id": "rgcABOTS3lXs0tkKksOpcmcb",
      "metadata": {
        "tags": [],
        "id": "rgcABOTS3lXs0tkKksOpcmcb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f9abf77-946e-4977-c3c6-0ff79589b75d"
      },
      "source": [
        "!pip install --quiet --upgrade google-cloud-logging google_cloud_firestore google_cloud_aiplatform langchain langchain-google-vertexai langchain_community langchain_experimental pymupdf"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.5/229.5 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m67.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m60.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.7/102.7 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m90.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.2/209.2 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.1/24.1 MB\u001b[0m \u001b[31m72.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.9/438.9 kB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m364.6/364.6 kB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 MB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.7/44.7 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. After the cell completes running, indicated by a checkmark to the left of the cell, the packages should be installed. To use them, restart the runtime.\n",
        "\n",
        "6. Import the following packages by running the following command:"
      ],
      "metadata": {
        "id": "THfHzd3Br4Vw"
      },
      "id": "THfHzd3Br4Vw"
    },
    {
      "cell_type": "code",
      "source": [
        "import vertexai\n",
        "import logging\n",
        "import google.cloud.logging\n",
        "from vertexai.language_models import TextEmbeddingModel\n",
        "from vertexai.generative_models import GenerativeModel\n",
        "\n",
        "import pickle\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "from langchain_google_vertexai import VertexAIEmbeddings\n",
        "from langchain_community.document_loaders import PyMuPDFLoader\n",
        "from langchain_experimental.text_splitter import SemanticChunker\n",
        "\n",
        "from google.cloud import firestore\n",
        "from google.cloud.firestore_v1.vector import Vector\n",
        "from google.cloud.firestore_v1.base_vector_query import DistanceMeasure"
      ],
      "metadata": {
        "id": "FRp5UjuUryuI"
      },
      "id": "FRp5UjuUryuI",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Next, initialize Vertex AI with your project-id qwiklabs-gcp-01-e6855b6ff8c2 and a location of us-central1"
      ],
      "metadata": {
        "id": "FTKSdZTlsc48"
      },
      "id": "FTKSdZTlsc48"
    },
    {
      "cell_type": "code",
      "source": [
        "PROJECT_ID = \"qwiklabs-gcp-01-e6855b6ff8c2\"\n",
        "LOCATION = \"us-central1\"\n",
        "import vertexai\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)"
      ],
      "metadata": {
        "id": "GWpa669IsG_w"
      },
      "id": "GWpa669IsG_w",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Populate a variable named embedding_model with an instance of the langchain_google_vertexai class VertexAIEmbeddings. Pass it a parameter model_name set to the text embedding model version of text-embedding-005. You will use this LangChain class for your embedding model so that you can use a LangChain semantic chunker to chunk your dataset."
      ],
      "metadata": {
        "id": "gDxbdOAEs1mp"
      },
      "id": "gDxbdOAEs1mp"
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_model = VertexAIEmbeddings(model_name=\"text-embedding-005\")"
      ],
      "metadata": {
        "id": "GID1ka1bs0tl"
      },
      "id": "GID1ka1bs0tl",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 2. Download, process and chunk data semantically\n",
        "In this section, you will prepare the NYC Food Safety Manual for Retrieval-Augmented Generation (RAG). Clean the PDF content and split it into meaningful chunks based on semantic similarity using sentence embeddings and generate numerical representations (embeddings) for each identified text chunk.\n",
        "\n",
        "1. Download the New York City Department of Health and Mental Hygiene's Food Protection Training Manual. This document will serve as your Retrieval-Augmented Generation source content."
      ],
      "metadata": {
        "id": "SiovGq8Et5Xf"
      },
      "id": "SiovGq8Et5Xf"
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud storage cp gs://partner-genai-bucket/genai069/nyc_food_safety_manual.pdf ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5P1wJ-vtJOt",
        "outputId": "e4724cab-cfa2-4704-da6d-a2584c3c94d4"
      },
      "id": "N5P1wJ-vtJOt",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying gs://partner-genai-bucket/genai069/nyc_food_safety_manual.pdf to file://./nyc_food_safety_manual.pdf\n",
            "\n",
            "Average throughput: 159.9MiB/s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -al"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThR9IqYquDsv",
        "outputId": "ca1184bd-24bb-476a-bc7d-f0d5d20bf19f"
      },
      "id": "ThR9IqYquDsv",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 8704\n",
            "drwxr-xr-x 3 root root    4096 Jun 22 17:38 .\n",
            "drwxr-xr-x 1 root root    4096 Jun 22 17:26 ..\n",
            "drwxr-xr-x 5 root root    4096 Jun 22 17:38 .config\n",
            "-rw-r--r-- 1 root root 8898262 Jun 22 17:38 nyc_food_safety_manual.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Use the LangChain class PyMuPDFLoader to load the contents of the PDF to a variable named data"
      ],
      "metadata": {
        "id": "D_ad2YKpuKoL"
      },
      "id": "D_ad2YKpuKoL"
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace with your PDF file path\n",
        "file_path = \"nyc_food_safety_manual.pdf\"\n",
        "\n",
        "# Instantiate the loader\n",
        "loader = PyMuPDFLoader(file_path)\n",
        "\n",
        "# Load the document\n",
        "data = loader.load()\n",
        "\n",
        "# 'data' now holds the loaded document content\n",
        "#  You can access the content of each page using data[i].page_content\n",
        "#  and metadata using data[i].metadata\n",
        "\n",
        "print(data[0].page_content[:200]) # Print the first 200 chars of the first page content.\n",
        "print(data[0].metadata) # Print the metadata of the first page."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ciGUAxHXt_rm",
        "outputId": "c849159a-c219-4ddf-dce8-ebd6929ee06b"
      },
      "id": "ciGUAxHXt_rm",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Health Code\n",
            "These are regulations that were\n",
            "formulated to allow the  Department\n",
            "to effectively protect the health of the\n",
            "population. Among the rules\n",
            "embodied in the Health Code is\n",
            "Article 81 which\n",
            "{'producer': 'Acrobat Distiller 8.0.0 (Macintosh)', 'creator': 'QuarkXPress 8.5', 'creationdate': '2014-06-24T12:42:42-04:00', 'source': 'nyc_food_safety_manual.pdf', 'file_path': 'nyc_food_safety_manual.pdf', 'total_pages': 94, 'format': 'PDF 1.6', 'title': 'FOR BIND Food Protect Manual rev6 14_Conv-Sig', 'author': 'Hizzoner', 'subject': '', 'keywords': '', 'moddate': '2015-11-12T10:57:27-05:00', 'trapped': '', 'modDate': \"D:20151112105727-05'00'\", 'creationDate': \"D:20140624124242-04'00'\", 'page': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. The following function is provided to do some basic cleaning on artifacts found in this particular document. Create a variable called 'cleaned_pages' that is a list of strings, with each string being a page of content cleaned by this function."
      ],
      "metadata": {
        "id": "wmz86vsRvzTl"
      },
      "id": "wmz86vsRvzTl"
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_page(page):\n",
        "  return page.page_content.replace(\"-\\n\",\"\")\\\n",
        "                          .replace(\"\\n\",\" \")\\\n",
        "                          .replace(\"\\x02\",\"\")\\\n",
        "                          .replace(\"\\x03\",\"\")\\\n",
        "                          .replace(\"fo d P R O T E C T I O N  T R A I N I N G  M A N U A L\",\"\")\\\n",
        "                          .replace(\"N E W  Y O R K  C I T Y  D E P A R T M E N T  O F  H E A L T H  &  M E N T A L  H Y G I E N E\",\"\")"
      ],
      "metadata": {
        "id": "YkST9GtvviRn"
      },
      "id": "YkST9GtvviRn",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a variable called 'cleaned_pages' that is a list of strings, with each string being a page of content cleaned by this function clean_page().\n",
        "cleaned_pages = [clean_page(page) for page in data]\n",
        "\n",
        "# optionally print-out the first cleaned page to verify\n",
        "print(cleaned_pages[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SgCu_-Ov4AQ",
        "outputId": "0059e537-4485-4dc4-f1d1-523d77319422"
      },
      "id": "9SgCu_-Ov4AQ",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Health Code These are regulations that were formulated to allow the  Department to effectively protect the health of the population. Among the rules embodied in the Health Code is Article 81 which regulates the operations of food establishments for the purpose of preventing public health hazards. Environmental Health Division  The Division of Environmental Health is the Commission within the Health Department that is concerned with public health and works to eliminate the incidence of injury and illness caused by environmental factors. There are several Offices and Bureaus within this division. One of these is the Bureau of Food Safety and Community Sanitation that has the responsibility for conducting inspections of food service and food processing establishments. These inspections are performed by Public Health Sanitarians. Anti-corruption Warning All Sanitarians have Department of Health and Mental Hygiene badges and identification cards which they must display whenever it is requested of them. It is illegal to offer a Sanitarian any bribe, gratuity or reward for official misconduct; this is a crime that can result in fines, and /or imprisonment, and the revocation of permits. Also, Sanitarians are not authorized to conduct any monetary transactions on behalf of the Department. Inspector General This is an office that exists within the Health Department with the responsibility of investigating any incidence of alleged corrupt activity. Investigations may be conducted as a result of complaints by employees of the Department or members of the public. Health Academy The Health Academy is an office within the Division of Environmental Health. One of its responsibilities is to provide training and certification courses for individuals from the public as mandated by the Health Code. The Food Protection Course is one of the courses taught here. The Food Protection Course is required by the Health Code for supervisors of food service establishments and non-retail food processing establishments. These individuals must take the course and pass an examination before a certificate is issued to them. A person holding such a certificate must be on the premises and supervise all food preparation activities during all hours of operation. Several supervisors with this certification may be needed at an establishment to have coverage during all shifts, vacations or illnesses. The Food Protection Manual has been designed to assist participants of the course to better understand the principles of safe food handling. It serves as a reference for food service operators and it includes the necessary information to pass the final examination. On-Line Food Protection Course The Food Protection Course in English, Spanish and Chinese is now also available on-line. This course is designed for individuals with busy schedules to study at their convenience. After the completion of the course, a final examination is scheduled at the Health Academy. Registration is done on-line. The link is: nyc.gov/foodprotectioncourse Register for Health Academy Classes On-Line You may now register and pay online for courses offered at the Department of Health and Mental Hygiene’s Health Academy, including the Food Protection Course for restaurants. This new service allows you to avoid going to the Citywide Licensing Center to register for a course. You may also use the on-line service to pay for and request an appointment to replace your Food Protection Certificate. How does it work? Go to the registration web page, nyc.gov/healthacademy, select a course and date, pay the appropriate fee and receive confirmation.  You will be asked to provide some personal information before registering. In most cases, you will be able to select from a list of course dates. If you don’t see a date that is convenient, check back as new course dates are added frequently. 1   INTRODUCTION T he New York City Department of Health and Mental Hygiene has the jurisdiction to regulate all matters affecting health in the city and to perform all those functions and operations that relate to the health of the people of the city. INTRODUCTION\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Use LangChain's SemanticChunker with the embedding_model you created earlier to split the first five pages of cleaned_pages into text chunks. The SemanticChunker determines when to start a new chunk when it encounters a larger distance between sentence embeddings. Save the strings of page content from the resulting documents into a list of strings called chunked_content. Take a look at a few of the chunks to get familiar with the content."
      ],
      "metadata": {
        "id": "IFzIFLnK1VtI"
      },
      "id": "IFzIFLnK1VtI"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.documents import Document\n",
        "from langchain_experimental.text_splitter import SemanticChunker\n",
        "\n",
        "# Select the first five pages from 'cleaned_pages'\n",
        "first_five_cleaned_pages = cleaned_pages[:5]\n",
        "\n",
        "# Convert the list of strings back into a list of Document objects for SemanticChunker\n",
        "# SemanticChunker typically works with Document objects, not raw strings directly.\n",
        "documents_to_chunk = [Document(page_content=text) for text in first_five_cleaned_pages]\n",
        "\n",
        "# Instantiate SemanticChunker with the embedding_model\n",
        "# The 'breakpoint_threshold_type' parameter can be set to 'percentile' or 'standard_deviation'\n",
        "# 'percentile' is a common choice, meaning it breaks when the distance is above a certain percentile.\n",
        "text_splitter = SemanticChunker(\n",
        "    embeddings=embedding_model,\n",
        "    breakpoint_threshold_type=\"percentile\" # You can experiment with \"standard_deviation\" as well\n",
        ")\n",
        "\n",
        "# Split the documents into chunks\n",
        "chunked_documents = text_splitter.split_documents(documents_to_chunk)\n",
        "\n",
        "# Save the strings of page content from the resulting documents into a list of strings called 'chunked_content'\n",
        "chunked_content = [doc.page_content for doc in chunked_documents]\n",
        "\n",
        "# Take a look at a few of the chunks to get familiar with the content.\n",
        "print(f\"Number of chunks created: {len(chunked_content)}\\n\")\n",
        "\n",
        "print(\"--- First chunk ---\")\n",
        "print(chunked_content[0])\n",
        "print(\"\\n--- Second chunk ---\")\n",
        "print(chunked_content[1])\n",
        "print(\"\\n--- Third chunk ---\")\n",
        "print(chunked_content[2])\n",
        "print(\"\\n--- Last chunk of the first five pages ---\")\n",
        "# Print the last chunk if there are enough, otherwise print the last available.\n",
        "if len(chunked_content) > 3:\n",
        "    print(chunked_content[-1])\n",
        "else:\n",
        "    print(\"Not enough chunks to print the 'last chunk of the first five pages'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUVaA0ru0cez",
        "outputId": "81115ee1-8f0c-4187-edcf-465cdc6ca709"
      },
      "id": "oUVaA0ru0cez",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of chunks created: 15\n",
            "\n",
            "--- First chunk ---\n",
            "The Health Code These are regulations that were formulated to allow the  Department to effectively protect the health of the population. Among the rules embodied in the Health Code is Article 81 which regulates the operations of food establishments for the purpose of preventing public health hazards. Environmental Health Division  The Division of Environmental Health is the Commission within the Health Department that is concerned with public health and works to eliminate the incidence of injury and illness caused by environmental factors. There are several Offices and Bureaus within this division. One of these is the Bureau of Food Safety and Community Sanitation that has the responsibility for conducting inspections of food service and food processing establishments. These inspections are performed by Public Health Sanitarians. Anti-corruption Warning All Sanitarians have Department of Health and Mental Hygiene badges and identification cards which they must display whenever it is requested of them. It is illegal to offer a Sanitarian any bribe, gratuity or reward for official misconduct; this is a crime that can result in fines, and /or imprisonment, and the revocation of permits. Also, Sanitarians are not authorized to conduct any monetary transactions on behalf of the Department. Inspector General This is an office that exists within the Health Department with the responsibility of investigating any incidence of alleged corrupt activity. Investigations may be conducted as a result of complaints by employees of the Department or members of the public. Health Academy The Health Academy is an office within the Division of Environmental Health. One of its responsibilities is to provide training and certification courses for individuals from the public as mandated by the Health Code. The Food Protection Course is one of the courses taught here. The Food Protection Course is required by the Health Code for supervisors of food service establishments and non-retail food processing establishments. These individuals must take the course and pass an examination before a certificate is issued to them. A person holding such a certificate must be on the premises and supervise all food preparation activities during all hours of operation. Several supervisors with this certification may be needed at an establishment to have coverage during all shifts, vacations or illnesses. The Food Protection Manual has been designed to assist participants of the course to better understand the principles of safe food handling. It serves as a reference for food service operators and it includes the necessary information to pass the final examination. On-Line Food Protection Course The Food Protection Course in English, Spanish and Chinese is now also available on-line. This course is designed for individuals with busy schedules to study at their convenience. After the completion of the course, a final examination is scheduled at the Health Academy.\n",
            "\n",
            "--- Second chunk ---\n",
            "Registration is done on-line. The link is: nyc.gov/foodprotectioncourse Register for Health Academy Classes On-Line You may now register and pay online for courses offered at the Department of Health and Mental Hygiene’s Health Academy, including the Food Protection Course for restaurants. This new service allows you to avoid going to the Citywide Licensing Center to register for a course. You may also use the on-line service to pay for and request an appointment to replace your Food Protection Certificate. How does it work? Go to the registration web page, nyc.gov/healthacademy, select a course and date, pay the appropriate fee and receive confirmation. You will be asked to provide some personal information before registering. In most cases, you will be able to select from a list of course dates.\n",
            "\n",
            "--- Third chunk ---\n",
            "If you don’t see a date that is convenient, check back as new course dates are added frequently. 1   INTRODUCTION T he New York City Department of Health and Mental Hygiene has the jurisdiction to regulate all matters affecting health in the city and to perform all those functions and operations that relate to the health of the people of the city. INTRODUCTION\n",
            "\n",
            "--- Last chunk of the first five pages ---\n",
            "They are filter feeders, that is, they absorb water from their environment, filter out whatever nutrients are there and then expel the water. Feeding in this manner causes them to absorb and accumulate harmful microorganisms from polluted waters. Since the whole shellfish is eaten either raw or partially cooked, it is critical to ensure that they are harvested from safe waters. It is important to buy shellfish from reputable suppliers who can provide the shipper’s tags which identify the source of the shellfish. These tags supply the following information:  The name of the product  The name of the original shipper  The address of the original shipper  The interstate certificate number of the original shipper  The location of the shellfish harvesting area. When purchasing small amounts from a retailer, a tag must be provided. This is a split-lot tag which has all the information that is on the original tag. The shellfish tag is required to be kept together with the product, then whenever the product is used up, it must be kept for 90 days in order of delivery. The virus Hepatitis A is associated with shellfish. Check if the shellfish is alive. An opened shell may be an indication of dead shellfish. Gently tap on the shell, if the shell closes then it is alive otherwise it’s dead and should be discarded. Both alive as well as shucked shellfish (shellfish that has been removed from its shell) must only be accepted if delivered at a temperature of 41°F or below. Following conditions would automatically be grounds for rejection:  Slimy, sticky or dry texture  Strong fishy odor  Broken shells Other Shellfish Lobsters, crabs and shrimps belong to the family of crustaceans. Fresh lobsters and crabs must be alive at the time of delivery. As with other seafood, a strong fishy odor is an indication of spoilage. The shell of the shrimp must be intact and firmly attached. All processed crustacean must be delivered at 41°F or below. Eggs Eggs produced outside of New York State are inspected by the U.S. Department of Agriculture while those produced within the State are inspected by the New York State Department of Agriculture and Markets. In either case, inspected eggs will be identified by a stamp on the carton. Eggs have long been 5   Split Lot Tag Shellfish Tag It is strongly recommended that the invoices be kept with the tags to aid in tracing the lot’s history.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Use the embedding_model to generate embeddings of the text chunks, saving them to a list called chunked_embeddings. To do so, pass your list of chunks to the VertexAIEmbeddings class's embed_documents() method."
      ],
      "metadata": {
        "id": "65Pw0jd72E4f"
      },
      "id": "65Pw0jd72E4f"
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming the previous code blocks have been executed and necessary variables are defined:\n",
        "# - embedding_model (an instance of VertexAIEmbeddings)\n",
        "# - chunked_content (list of strings, where each string is a text chunk)\n",
        "\n",
        "# Generate embeddings for the text chunks\n",
        "# The embed_documents() method expects a list of strings\n",
        "chunked_embeddings = embedding_model.embed_documents(chunked_content)\n",
        "\n",
        "# Verify the number of embeddings generated matches the number of chunks\n",
        "print(f\"Number of chunks: {len(chunked_content)}\")\n",
        "print(f\"Number of embeddings generated: {len(chunked_embeddings)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEFbUOoB1csc",
        "outputId": "0a894367-122f-47b1-d627-86918698d161"
      },
      "id": "oEFbUOoB1csc",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of chunks: 15\n",
            "Number of embeddings generated: 15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Optionally: print-out the first chunked_content to see its structure (it will be a list of floats)\n",
        "print(\"\\nFirst chunked_content (first few dimensions):\")\n",
        "print(chunked_content[0][:10]) # Print only the first 10 dimensions for brevity\n",
        "print(f\"Dimension of chunked_content: {len(chunked_content[0])}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxPPqG0h2I-S",
        "outputId": "d19ffb9a-bfc1-4470-909f-72560b2aeebe"
      },
      "id": "BxPPqG0h2I-S",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "First chunked_content (first few dimensions):\n",
            "The Health\n",
            "Dimension of chunked_content: 2976\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Optionally: print-out the first embedding to see its structure (it will be a list of floats)\n",
        "print(\"\\nFirst embedding (first few dimensions):\")\n",
        "print(chunked_embeddings[0][:10]) # Print only the first 10 dimensions for brevity\n",
        "print(f\"Dimension of embeddings: {len(chunked_embeddings[0])}\")"
      ],
      "metadata": {
        "id": "QmcjrYBu4ovI"
      },
      "id": "QmcjrYBu4ovI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. You should have successfully chunked & embedded a short section of the document. To get the chunks & corresponding embeddings for the full document, run the following code:"
      ],
      "metadata": {
        "id": "AYbRvnDA2e96"
      },
      "id": "AYbRvnDA2e96"
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud storage cp gs://partner-genai-bucket/genai069/chunked_content.pkl .\n",
        "!gcloud storage cp gs://partner-genai-bucket/genai069/chunked_embeddings.pkl .\n",
        "\n",
        "chunked_content = pickle.load(open(\"chunked_content.pkl\", \"rb\"))\n",
        "chunked_embeddings = pickle.load(open(\"chunked_embeddings.pkl\", \"rb\"))\n",
        "\n",
        "# Do not delete this logging statement.\n",
        "client = google.cloud.logging.Client()\n",
        "client.setup_logging()\n",
        "log_message = f\"chunked contents are: {chunked_content[0][:20]}\"\n",
        "logging.info(log_message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKRQHVWL2PpQ",
        "outputId": "b646c5d3-0168-42eb-8730-8c9059ea89e5"
      },
      "id": "VKRQHVWL2PpQ",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Copying gs://partner-genai-bucket/genai069/chunked_content.pkl to file://./chunked_content.pkl\n",
            "Copying gs://partner-genai-bucket/genai069/chunked_embeddings.pkl to file://./chunked_embeddings.pkl\n",
            "\n",
            "Average throughput: 166.5MiB/s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:chunked contents are: The Health Code Thes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 3. Prepare your vector database\n",
        "In this section, you will set up a Firestore database to store the processed NYC Food Safety Manual chunks and their embeddings for efficient retrieval. You'll then build a search function to find relevant information based on a user query.\n",
        "\n",
        "1. Create a Firestore database with the default name of (default) in Native Mode and leave the other settings to default -> manual step (do this in the Google CLoud Console).\n",
        "\n",
        "2. Next, in your Colab Enterprise Notebook populate a 'db' variable with a Firestore Client.\n",
        "\n",
        "3. Use a variable called 'collection' to create a reference to a collection named **food-safety**."
      ],
      "metadata": {
        "id": "adJ72zg13Jan"
      },
      "id": "adJ72zg13Jan"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import firestore\n",
        "\n",
        "# Initialize Firestore client\n",
        "db = firestore.Client(project=PROJECT_ID)\n",
        "collection = db.collection(\"food-safety\")"
      ],
      "metadata": {
        "id": "_3EqEtJ62nVM"
      },
      "id": "_3EqEtJ62nVM",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(PROJECT_ID)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kexgwfOn7LID",
        "outputId": "72cd8c29-d72e-438a-d89d-fe5de0abf9f9"
      },
      "id": "kexgwfOn7LID",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "qwiklabs-gcp-01-e6855b6ff8c2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Using a combination of your lists 'chunked_content' and 'chunked_embeddings', add a document to your collection for each of your chunked documents. Each document can be assigned a random ID, but it should have a field called content to store the chunk text and a field called embedding to store a Firestore Vector() of the associated embedding."
      ],
      "metadata": {
        "id": "9vjTw0cP38Mr"
      },
      "id": "9vjTw0cP38Mr"
    },
    {
      "cell_type": "code",
      "source": [
        "# Store each embedding and chunk\n",
        "for i, (embedding, chunk) in enumerate(zip(chunked_embeddings, chunked_content)):\n",
        "    doc = {\n",
        "        \"embedding\": embedding,\n",
        "        \"chunk\": chunk\n",
        "    }\n",
        "    collection.document(f\"chunk_{i}\").set(doc)"
      ],
      "metadata": {
        "id": "i6AsNaue3zOa"
      },
      "id": "i6AsNaue3zOa",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Create a vector index for your collection using your embedding field.\n",
        "\n",
        "**Note-1:** A find_nearest() operation cannot be executed on a collection without an index. When attempted, the system will return an error message including instructions to create the index using a gcloud command.\n",
        "\n",
        "**Note-2:** For index creation we need to use this 'gcloud' command in the CLoud Shell\n",
        "\n",
        "gcloud firestore indexes composite create \\\n",
        "--collection-group=collection-group \\\n",
        "--query-scope=COLLECTION \\\n",
        "--field-config field-path=vector-field,vector-config='vector-configuration' \\\n",
        "--database=database-id"
      ],
      "metadata": {
        "id": "mnNwTkNH5GR7"
      },
      "id": "mnNwTkNH5GR7"
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud firestore indexes composite create \\\n",
        "    --collection-group=food-safety \\\n",
        "    --query-scope=COLLECTION \\\n",
        "    --field-config field-path=embedding,vector-config='{\"dimension\":\"768\", \"flat\": \"{}\"}' \\\n",
        "    --database=\"(default)\" \\\n",
        "    --project=qwiklabs-gcp-01-e6855b6ff8c2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkxVBLAf4-re",
        "outputId": "96fdd752-549f-4208-a38b-5277bf57373d"
      },
      "id": "wkxVBLAf4-re",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create request issued\n",
            "Created index [CICAgOjXh4EK].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Complete the function below to receive a query, get its embedding, and compile a context consisting of the text from the 5 documents with the most similar embeddings. This time, use the embed_query() method of the LangChain 'VertexAIEmbeddings' embedding_model to embed the user's query."
      ],
      "metadata": {
        "id": "Xt_zt5iZA-s9"
      },
      "id": "Xt_zt5iZA-s9"
    },
    {
      "cell_type": "code",
      "source": [
        "def search_vector_database(query: str):\n",
        "\n",
        "  context = \"\"\n",
        "\n",
        "  # 1. Generate the embedding of the query\n",
        "  query_embedding_list = embedding_model.embed_query(query)\n",
        "\n",
        "  # Firestore expects Vector objects for vector search\n",
        "  query_vector = Vector(query_embedding_list)\n",
        "\n",
        "  # 2. Get the 5 nearest neighbors from your collection.\n",
        "  # Call the get() method on the result of your call to\n",
        "  # find_nearest to retrieve document snapshots.\n",
        "\n",
        "  # The find_nearest method typically expects the vector field name, the query vector,\n",
        "  # the distance measure, and the limit.\n",
        "  nearest_neighbors = collection.find_nearest(\n",
        "      vector_field=\"embedding\",\n",
        "      query_vector=query_vector,\n",
        "      distance_measure=DistanceMeasure.COSINE, # Use COSINE as discussed for text-embedding-005\n",
        "      limit=5\n",
        "  ).get() # .get() retrieves the actual document snapshots\n",
        "\n",
        "\n",
        "  # 3. Call to_dict() on each snapshot to load its data.\n",
        "  # Combine the snapshots into a single string named context\n",
        "  for snapshot in nearest_neighbors:\n",
        "    doc_data = snapshot.to_dict()\n",
        "    if doc_data and \"chunk\" in doc_data:\n",
        "      context += doc_data[\"chunk\"] + \"\\n\\n\" # Add a newline for separation between chunks\n",
        "\n",
        "\n",
        "  return context"
      ],
      "metadata": {
        "id": "RS9sk-9bAx3A"
      },
      "id": "RS9sk-9bAx3A",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Next, call the function with the query How should I store food? to confirm it's functionality."
      ],
      "metadata": {
        "id": "Kai6ERnTB2tl"
      },
      "id": "Kai6ERnTB2tl"
    },
    {
      "cell_type": "code",
      "source": [
        "print(search_vector_database(\"How should I store food?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExgEQ8wGBzUT",
        "outputId": "bf63185b-c20d-49a4-df04-fcdcd471ff06"
      },
      "id": "ExgEQ8wGBzUT",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 4. Deploy a Generative AI application to search your vector store\n",
        "Now that your vector database is prepared, in this section you will work on the client application to query it and return answers generated by Gemini."
      ],
      "metadata": {
        "id": "kLzPv9XAD0oJ"
      },
      "id": "kLzPv9XAD0oJ"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jbMpHHT5D9J-"
      },
      "id": "jbMpHHT5D9J-",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "name": "student-01-01bb569b9d1c (Jun 22, 2025, 10:25:20 AM)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}