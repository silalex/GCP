{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Compare Model Performance using the Generative AI Evaluation Service: Challenge Lab\n",
        "\n",
        "## GENAI063\n",
        "\n",
        "Link: https://partner.cloudskillsboost.google/course_templates/1130/labs/528777\n",
        "\n",
        "## Objective\n",
        "This lab challenges you to conduct a model-based, pairwise evaluation on two models tasked with completing the same tasks. You will use the Generative AI Evaluation Service to complete this evaluation.\n",
        "\n",
        "Link: https://cloud.google.com/vertex-ai/generative-ai/docs/models/evaluation-overview\n",
        "\n",
        "## Your Challenge\n",
        "You have been contracted by a movie production studio that wants to prepare for a series of low-budget short films. They’ve asked you to develop a generative AI tool to help them. They've provided you:\n",
        " - Some unstructured notes on different phases of production\n",
        " - A rate card which describes hourly rates for different crew positions on the films\n",
        "\n",
        "You know that Gemini Flash is a faster and lower-cost alternative to Gemini Pro, so you’d like to quantify its performance to see if it would be an adequate alternative to Gemini Pro on these complex tasks.\n",
        "\n",
        "## Task 1. Initialize Gen AI in a Colab Enterprise notebook"
      ],
      "metadata": {
        "id": "XD9XoYWGCPdW"
      },
      "id": "XD9XoYWGCPdW"
    },
    {
      "cell_type": "code",
      "id": "VJPS1vKCSEH4UlH7Lb9x9t2b",
      "metadata": {
        "tags": [],
        "id": "VJPS1vKCSEH4UlH7Lb9x9t2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cac44bb-cfa8-4bf8-fdd6-bde29bfdc97c"
      },
      "source": [
        "%pip install --upgrade --quiet google-genai nest-asyncio==1.5.9"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/206.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m206.4/206.4 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Clicking on the caret should reveal a set of menus above the notebook. Select **Runtime > Restart Session**. When asked to confirm, select Yes. The runtime will restart, indicated by clearing the green checkmark and the cell run order integer next to the cell you ran above."
      ],
      "metadata": {
        "id": "r22oKs28C1qc"
      },
      "id": "r22oKs28C1qc"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from inspect import cleandoc\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "import vertexai\n",
        "from vertexai.generative_models import GenerativeModel, GenerationConfig\n",
        "from vertexai.evaluation import (\n",
        "    MetricPromptTemplateExamples,\n",
        "    EvalTask,\n",
        "    PairwiseMetric,\n",
        "    PairwiseMetricPromptTemplate,\n",
        "    PointwiseMetric,\n",
        "    PointwiseMetricPromptTemplate,\n",
        ")\n",
        "\n",
        "pd.set_option(\"display.max_colwidth\", None)"
      ],
      "metadata": {
        "id": "XIq_eKqqCuD1"
      },
      "id": "XIq_eKqqCuD1",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TBD: In a new code block, initialize Gen AI with vertexai.init(). Use the us-west1 location and run the cell.\n",
        "PROJECT_ID = \"qwiklabs-gcp-04-ed6c67b5afd4\"\n",
        "LOCATION = \"us-west1\"\n",
        "import vertexai\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)"
      ],
      "metadata": {
        "id": "bbV7Q1vzC6K_"
      },
      "id": "bbV7Q1vzC6K_",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 2. Explore example data and generate a document\n",
        "\n",
        "In this task, you will set up some sample data for a film production including crew rates, shooting schedules and then define questions for a large language model to answer.\n",
        "\n",
        "1. Run the following code in a new cell to instantiate some example data. The calls to cleandoc() helps remove the indents and extra lines used for making the multi-line string readable in the code."
      ],
      "metadata": {
        "id": "YlY_dbnNDkf_"
      },
      "id": "YlY_dbnNDkf_"
    },
    {
      "cell_type": "code",
      "source": [
        "hourly_rates = cleandoc(\"\"\"\n",
        "  Screenwriter: $40\n",
        "  Actor: $25\n",
        "  Director: $30\n",
        "  Camera Operator: $35\n",
        "  Sound Engineer: $20\n",
        "  Editor: $30\n",
        "  \"\"\")\n",
        "\n",
        "planning_notes = cleandoc(\"\"\"\n",
        " Phases of Production:\n",
        "   Writing:\n",
        "   The Screenwriter will write the script.\n",
        "   They need 72 hours to do so.\n",
        "\n",
        "\n",
        " Pre-Production:\n",
        "   The Director needs time to analyze the script.\n",
        "   They will work on it for 36 hours.\n",
        "   The Camera Operator will join the director for 24 hours of planning.\n",
        "\n",
        "\n",
        " Production Phase 1\n",
        "   The first three days of filming will require the director, 4 actors, the camera operator, and the sound engineer\n",
        "\n",
        "\n",
        " Production Phase 2\n",
        "   The next three days of filming will require the director, 8 actors, the camera operator, and the sound engineer\n",
        "\n",
        "\n",
        " Post-Production\n",
        "   The editor will take 64 hours to edit the film.\n",
        "   The director will work with the editor for 24 hours during this phase.\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "HZITOX8jDbGC"
      },
      "id": "HZITOX8jDbGC",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.Run the following code to define the content we would like the model to help us with."
      ],
      "metadata": {
        "id": "TJHJRLyGD_Uu"
      },
      "id": "TJHJRLyGD_Uu"
    },
    {
      "cell_type": "code",
      "source": [
        "tasks = [\n",
        "    \"\"\"What is the cost of each phase of production?\n",
        "    If days are mentioned, assume an 8 hour work day.\"\"\",\n",
        "\n",
        "    \"\"\"How many days will each phase require? Assume an\n",
        "    8 hour work day. If multiple people are working in parallel,\n",
        "    do not add those times together, but only use the longest time.\n",
        "    Also include a count of the total number of days of the entire\n",
        "    project.\"\"\",\n",
        "\n",
        "    \"\"\"Prepare a text schedule for all phases of the film starting\n",
        "    on Feb 3, 2025. The whole crew should be off Saturdays\n",
        "    and Sundays.\"\"\"\n",
        "]"
      ],
      "metadata": {
        "id": "dwmuT14rD4CF"
      },
      "id": "dwmuT14rD4CF",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Next, define a prompt template."
      ],
      "metadata": {
        "id": "P55J08I8GTbN"
      },
      "id": "P55J08I8GTbN"
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = cleandoc(\"\"\"\n",
        "<instructions>\n",
        "  Prepare a document to fulfill the task based on the context provided.\n",
        "</instructions>\n",
        "<task>\n",
        "  {task}\n",
        "</task>\n",
        "<context>\n",
        "  {context}\n",
        "</context>\n",
        "  \"\"\")"
      ],
      "metadata": {
        "id": "f94jah7mEByn"
      },
      "id": "f94jah7mEByn",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. You will compare how the lower-cost Gemini Flash compares against Gemini Pro on these instruction tasks to determine which you should use for this project. Instantiate a model variable **llm_pro** to contain a generative model using **gemini-2.5-pro-preview-05-06** and a model variable **llm_flash** to contain a generative model using **gemini-2.0-flash-001**.\n",
        "\n",
        "5. Add a generation configuration to each model to set the **temperature to 0**."
      ],
      "metadata": {
        "id": "GiTvRI0XGqG9"
      },
      "id": "GiTvRI0XGqG9"
    },
    {
      "cell_type": "code",
      "source": [
        "llm_pro = GenerativeModel(\n",
        "  \"gemini-2.5-pro\",\n",
        "  generation_config={\n",
        "      \"temperature\": 0,\n",
        "      \"top_p\": 0.4,\n",
        "  },\n",
        ")\n",
        "\n",
        "llm_flash = GenerativeModel(\n",
        "  \"gemini-2.0-flash-001\",\n",
        "  generation_config={\n",
        "      \"temperature\": 0,\n",
        "      \"top_p\": 0.4,\n",
        "  },\n",
        ")"
      ],
      "metadata": {
        "id": "YCGlI1pBGYF4"
      },
      "id": "YCGlI1pBGYF4",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Combine hourly_rates and planning_notes (with a pair of line breaks as a separator) to form a context chunk."
      ],
      "metadata": {
        "id": "Z6ksaf5NIv5o"
      },
      "id": "Z6ksaf5NIv5o"
    },
    {
      "cell_type": "code",
      "source": [
        "context = hourly_rates + \"\\n\\n\" + planning_notes"
      ],
      "metadata": {
        "id": "CtpqiO09IuVB"
      },
      "id": "CtpqiO09IuVB",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Using the **prompt_template (???)** and the **context**, generate a response to the second task (tasks[1]) for each model (llm_pro and llm_flash). Use the Markdown() class imported from IPython.display to wrap the response text to render Gemini's responses, which are often formatted as Markdown strings.\n",
        "\n",
        "# Q: How to use 'prompt_template' in llm_pro.generate_content() ???"
      ],
      "metadata": {
        "id": "jf5VCmELI8Wx"
      },
      "id": "jf5VCmELI8Wx"
    },
    {
      "cell_type": "code",
      "source": [
        "# Check results for \"llm_pro\" model:\n",
        "Markdown(llm_pro.generate_content(context + \"\\n\\n\" + str(tasks[1])).text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 412
        },
        "id": "Au2Mgk_mI909",
        "outputId": "e7ad3131-0b4c-4ce2-aead-cd8eaf537473"
      },
      "id": "Au2Mgk_mI909",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Based on the information provided and assuming an 8-hour workday, here is the breakdown of days for each phase:\n\n**Writing:**\nThe Screenwriter works for 72 hours.\n*   72 hours / 8 hours per day = **9 days**\n\n**Pre-Production:**\nThe Director works for 36 hours, and the Camera Operator works in parallel for 24 of those hours. The phase is determined by the longest time commitment.\n*   36 hours / 8 hours per day = 4.5 days. Since a partial day is still a workday, this phase requires **5 days**.\n\n**Production Phase 1:**\nThis phase is explicitly stated to last for **3 days**.\n\n**Production Phase 2:**\nThis phase is explicitly stated to last for **3 days**.\n\n**Post-Production:**\nThe Editor works for 64 hours, and the Director works in parallel for 24 of those hours. The phase is determined by the longest time commitment.\n*   64 hours / 8 hours per day = **8 days**\n\n---\n\n### **Total Project Duration**\n\n*   **Writing:** 9 days\n*   **Pre-Production:** 5 days\n*   **Production Phase 1:** 3 days\n*   **Production Phase 2:** 3 days\n*   **Post-Production:** 8 days\n\n**Total Project Days: 28 days**"
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check results for \"llm_flash\" model:\n",
        "Markdown(llm_flash.generate_content(context + \"\\n\\n\" + str(tasks[1])).text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 553
        },
        "id": "ltbBzTLpKTpx",
        "outputId": "d33ae80f-32b0-4e2f-9514-1a4433ad979d"
      },
      "id": "ltbBzTLpKTpx",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Okay, let's break down the project timeline and costs:\n\n**Phase Durations (in days):**\n\n*   **Writing:**\n    *   Screenwriter: 72 hours / 8 hours/day = 9 days\n\n*   **Pre-Production:**\n    *   Director: 36 hours / 8 hours/day = 4.5 days\n    *   Camera Operator: 24 hours / 8 hours/day = 3 days\n    *   Since they work in parallel, the phase duration is the longer of the two: 4.5 days\n\n*   **Production Phase 1:**\n    *   Given: 3 days\n\n*   **Production Phase 2:**\n    *   Given: 3 days\n\n*   **Post-Production:**\n    *   Editor: 64 hours / 8 hours/day = 8 days\n    *   Director: 24 hours / 8 hours/day = 3 days\n    *   Since they work in parallel, the phase duration is the longer of the two: 8 days\n\n**Total Project Duration:**\n\n9 + 4.5 + 3 + 3 + 8 = 27.5 days\n\n**Summary:**\n\n*   **Writing:** 9 days\n*   **Pre-Production:** 4.5 days\n*   **Production Phase 1:** 3 days\n*   **Production Phase 2:** 3 days\n*   **Post-Production:** 8 days\n*   **Total Project Duration:** 27.5 days\n"
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 3. Prepare the Evaluation Dataset and EvalTask\n",
        "In this task, you will set up the data and scoring method to evaluate the models.\n",
        "\n",
        "1. You will evaluate the models' responses against each other by using Pairwise question answering quality. Note the user input fields in curly braces in this prompt, which are required to evaluate this metrics. You will use the Gemini Pro responses as your **baseline model response** and your Gemini Flash responses as your **responses**.\n",
        "\n",
        "2. Prepare a Pandas DataFrame with the fields needed for evaluation."
      ],
      "metadata": {
        "id": "KgnkrF_TLt7h"
      },
      "id": "KgnkrF_TLt7h"
    },
    {
      "cell_type": "code",
      "source": [
        "# The full prompt combines the prompt instructions you\n",
        "# created earlier with the context for each apartment.\n",
        "full_prompts = [str(record) + \"\\n\\n\" + context for record in tasks]\n",
        "\n",
        "print(full_prompts[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzAYYV4WLQ91",
        "outputId": "cb266655-71f6-4487-bb5a-01256f4b9be8"
      },
      "id": "WzAYYV4WLQ91",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "How many days will each phase require? Assume an \n",
            "    8 hour work day. If multiple people are working in parallel, \n",
            "    do not add those times together, but only use the longest time. \n",
            "    Also include a count of the total number of days of the entire \n",
            "    project.\n",
            "\n",
            "Screenwriter: $40\n",
            "Actor: $25\n",
            "Director: $30\n",
            "Camera Operator: $35\n",
            "Sound Engineer: $20\n",
            "Editor: $30\n",
            "\n",
            "Phases of Production:\n",
            "  Writing:\n",
            "  The Screenwriter will write the script.\n",
            "  They need 72 hours to do so.\n",
            "\n",
            "\n",
            "  Pre-Production:\n",
            "  The Director needs time to analyze the script.\n",
            "  They will work on it for 36 hours.\n",
            "  The Camera Operator will join the director for 24 hours of planning.\n",
            "\n",
            "\n",
            "  Production Phase 1\n",
            "  The first three days of filming will require the director, 4 actors, the camera operator, and the sound engineer\n",
            "\n",
            "\n",
            "  Production Phase 2\n",
            "  The next three days of filming will require the director, 8 actors, the camera operator, and the sound engineer\n",
            "\n",
            "\n",
            "  Post-Production\n",
            "  The editor will take 64 hours to edit the film.\n",
            "  The director will work with the editor for 24 hours during this phase.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_dataset = pd.DataFrame({\n",
        "    \"prompt\": full_prompts[:2],\n",
        "})\n",
        "\n",
        "print(eval_dataset[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 547
        },
        "id": "xZIjlUktOSQO",
        "outputId": "16951253-8402-4ebd-f109-4c7685c9be00"
      },
      "id": "xZIjlUktOSQO",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "0",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 0",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-2750619902>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m })\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4101\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4102\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4104\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 0"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dftxkAG4OaG5"
      },
      "id": "dftxkAG4OaG5",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "name": "student-01-62458df2e102 (Jun 24, 2025, 8:01:23 PM)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}