{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e321cff7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cfaecaec",
   "metadata": {},
   "source": [
    "### Deploy Stable Diffusion XL via the command line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189ed8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cloud Shell coomads:\n",
    "\n",
    "$ gcloud auth application-default login\n",
    "\n",
    "$ gcloud config set billing/quota_project qwiklabs-asl-04-1e4c51b2847c\n",
    "\n",
    "$ gcloud ai model-garden models deploy \\\n",
    "--model=\"stability-ai/stable-diffusion-xl-base@stable-diffusion-xl-base-1.0\" \\\n",
    "--region=\"us-central1\" \\\n",
    "--project=\"qwiklabs-asl-04-1e4c51b2847c\" \\\n",
    "--accept-eula \\\n",
    "--machine-type=\"g2-standard-8\" \\\n",
    "--accelerator-type=\"NVIDIA_L4\" \\\n",
    "--container-image-uri=\"us-docker.pkg.dev/deeplearning-platform-release/vertex-model-garden/pytorch-inference.cu125.0-1.ubuntu2204.py310\" \\\n",
    "--endpoint-display-name=\"stabilityai_stable-diffusion-xl-1-mg-one-click-deploy\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9c956c",
   "metadata": {},
   "source": [
    "### Deploy the Falcon Instruct Model\n",
    "\n",
    "Assessment question:\n",
    "\n",
    "Given that Falcon-instruct is being fine-tuned using PEFT, which of the following is a common technique used in PEFT to reduce the number of trainable parameters?\n",
    " - Training all the layers of the original Falcon model from scratch\n",
    " - Converting the model architecture to a recurrent neural network (RNN)\n",
    " - Adding small, trainable adapter layers to the existing Falcon model while freezing most of its original parameters  (+)\n",
    " - Using a significantly smaller training dataset compared to the original Falcon model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6410bd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import vertexai\n",
    "from vertexai import model_garden\n",
    "\n",
    "vertexai.init(project=\"qwiklabs-asl-04-1e4c51b2847c\", location=\"us-central1\")\n",
    "\n",
    "model = model_garden.OpenModel(\"tiiuae/falcon-instruct-7b-peft@falcon-7b-instruct\")\n",
    "endpoint = model.deploy(\n",
    "  accept_eula=True,\n",
    "  machine_type=\"g2-standard-12\",\n",
    "  accelerator_type=\"NVIDIA_L4\",\n",
    "  accelerator_count=1,\n",
    "  serving_container_image_uri=\"us-docker.pkg.dev/vertex-ai/vertex-vision-model-garden-dockers/pytorch-vllm-serve:20240620_1616_RC00\",\n",
    "  endpoint_display_name=\"falcon-instruct-7b-peft-deploy-challenge-lab\",\n",
    "  model_display_name=\"falcon-instruct-7b-peft-001-1750287659003\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0934302a",
   "metadata": {},
   "source": [
    "### Deploy a Model to the same endpoint\n",
    "\n",
    "Assessment question:\n",
    "\n",
    "Which of the following contribute to Vertex AI custom model deployment (select all that apply)?\n",
    " - Model registry\n",
    " - Accelerators (+)\n",
    " - Virtual machine price per hour (+)\n",
    " - Disks (+)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9474e4e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "11f03d5a",
   "metadata": {},
   "source": [
    "### Test the CodeGemma deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b86a302",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.cloud.logging\n",
    "import logging\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "# Do not remove logging section\n",
    "client = google.cloud.logging.Client()\n",
    "client.setup_logging()\n",
    "\n",
    "\n",
    "# Replace your project number and endpoint id\n",
    "\n",
    "endpoint_resource_name=\"projects/1034013642830/locations/us-central1/endpoints/6552857304591499264\"\n",
    "endpoint=aiplatform.Endpoint(endpoint_resource_name)\n",
    "\n",
    "prompt = \"Write a function to list n Fibonacci numbers in Python.\" \n",
    "max_tokens = 500 \n",
    "temperature = 1.0 \n",
    "top_p = 1.0  \n",
    "top_k = 1 \n",
    "\n",
    "instances = [\n",
    "    # {\n",
    "    # Fill in the appropriate configuration\n",
    "    # },\n",
    "    {\n",
    "          \"@requestFormat\": \"chatCompletions\",\n",
    "          \"messages\": [\n",
    "              {\n",
    "                  \"role\": \"user\",\n",
    "                  \"content\": prompt\n",
    "              }\n",
    "          ],\n",
    "          \"max_tokens\": max_tokens,\n",
    "          \"temperature\": temperature,\n",
    "          \"top_p\": top_p,\n",
    "          \"top_k\": top_k\n",
    "    }\n",
    "]\n",
    "#response = endpoints[\"hexllm_tpu\"].predict(\n",
    "response = endpoint.predict(\n",
    "    instances=instances\n",
    ")\n",
    "\n",
    "# \"<|file_separator|>\" is the end of the file token.\n",
    "# for prediction in response.predictions:\n",
    "#     print(prediction.split(\"<|file_separator|>\")[0])\n",
    "\n",
    "\n",
    "print(response.deployed_model_id)\n",
    "\n",
    "# Do not remove logging section\n",
    "log_message = f\"Fibonacci function: {response}\"\n",
    "logging.info(log_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346fdbd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c1a23548",
   "metadata": {},
   "source": [
    "### Test the Stable Diffusion XL deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eedacf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from io import BytesIO\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def base64_to_image(image_str):\n",
    "    \"\"\"Convert base64 encoded string to an image.\"\"\"\n",
    "    image = Image.open(BytesIO(base64.b64decode(image_str)))\n",
    "    return image\n",
    "\n",
    "\n",
    "def image_grid(imgs, rows=2, cols=2):\n",
    "    w, h = imgs[0].size\n",
    "    grid = Image.new(\n",
    "        mode=\"RGB\", size=(cols * w + 10 * cols, rows * h), color=(255, 255, 255)\n",
    "    )\n",
    "    for i, img in enumerate(imgs):\n",
    "        grid.paste(img, box=(i % cols * w + 10 * i, i // cols * h))\n",
    "    return grid\n",
    "\n",
    "# Replace your project number and endpoint id\n",
    "endpoint_resource_name=\"projects/1034013642830/locations/us-central1/endpoints/mg-endpoint-1750285630\"\n",
    "endpoint=aiplatform.Endpoint(endpoint_resource_name)\n",
    "\n",
    "\n",
    "instances = [\n",
    "    {\n",
    "        \"prompt\": \" Generate a photorealistic image of a happy dog running\",\n",
    "        \"height\": 1024,\n",
    "        \"width\": 1024,\n",
    "    },\n",
    "]\n",
    "response = endpoint.predict(instances=instances)\n",
    "\n",
    "# Do not remove logging section\n",
    "log_message = f\"photorealistic image: {response}\"\n",
    "logging.info(log_message)\n",
    "\n",
    "images = [\n",
    "    base64_to_image(response.predictions[0]),\n",
    "]\n",
    "image_grid(images, rows=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3f6423",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "371db4c7",
   "metadata": {},
   "source": [
    "### Test the Falcon deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c366e1c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
