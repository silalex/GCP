{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca131e67",
   "metadata": {},
   "source": [
    "# Code Execution with Gemini\n",
    "\n",
    "[Lab link](https://partner.cloudskillsboost.google/paths/2294/course_templates/1235/labs/527178)\n",
    "\n",
    "Note: this ipy-notebook was created step-by-spet according to the lab instructions (there is no a template file is ready to use)\n",
    "\n",
    "### Objective\n",
    "\n",
    "In this lab, you will learn how to generate and execute code using the Gemini API in Vertex AI and the Google Gen AI SDK for Python with the Gemini 2.0 Flash model.\n",
    "\n",
    "You will complete the following tasks:\n",
    " - Generate and run sample Python code from text prompts.\n",
    " - Explore data using code execution in multi-turn chats.\n",
    " - Use code execution in streaming sessions.\n",
    "\n",
    " ### Task 1. Initialize the Google Gen AI SDK in a Colab Enterprise notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e3ce61",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "# Install the Google Gen AI SDK and restart the kernel\n",
    "%pip install --upgrade --quiet google-\n",
    "\n",
    "# After the cell completes running, indicated by a checkmark to the left of the cell, \n",
    "# the new packages should be installed. To use them, restart the runtime by selecting Runtime \n",
    "# from the menu bar and clicking Restart Session. \n",
    "#\n",
    "# When asked to confirm, select Yes. The runtime will restart, indicated by clearing the green checkmark \n",
    "# and the integer next to the cell above representing the order in which the cells have run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689e5a03",
   "metadata": {},
   "source": [
    "### Task 2. Initialize the Google Gen AI SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab5dc2d",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from IPython.display import HTML, Markdown, display\n",
    "from google import genai\n",
    "from google.genai.types import GenerateContentConfig, Tool, ToolCodeExecution, Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855161fb",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = os.environ.get(\"GOOGLE_CLOUD_PROJECT\")\n",
    "LOCATION = os.environ.get(\"GOOGLE_CLOUD_REGION\", \"us-central1\")\n",
    "\n",
    "client = genai.Client(vertexai=True, project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d90ff1",
   "metadata": {},
   "source": [
    "### Task 3. Generate and execute code with Gemini 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038f24f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the code execution tool you imported above:\n",
    "code_execution_tool = Tool(code_execution=ToolCodeExecution())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182896fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a prompt to instruct the model to generate code. Note that the model decides \n",
    "# when to use tools such as code generation (as opposed to returning code as text, \n",
    "# for example), so your prompt is important to direct the model to do what you would like:\n",
    "\n",
    "PROMPT = \"\"\"\n",
    "What is the sum of the first 50 prime numbers?\n",
    "Generate and run code for the calculation.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ca2627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the following to send the prompt to the model. \n",
    "# Note that the code execution tool is passed to the request so the model can use it:\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash-001\",\n",
    "    contents=PROMPT,\n",
    "    config=GenerateContentConfig(\n",
    "        tools=[code_execution_tool],\n",
    "        temperature=0,\n",
    "    ),\n",
    ")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d794bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following code iterates through the response and displays any generated Python code\n",
    "# by checking for part.executable_code in the response parts:\n",
    "\n",
    "for part in response.candidates[0].content.parts:\n",
    "    if part.executable_code:\n",
    "        print(part.executable_code.code)\n",
    "\n",
    "\n",
    "'''\n",
    "Output:\n",
    "\n",
    "def is_prime(n):\n",
    "    if n <= 1:\n",
    "        return False\n",
    "    if n <= 3:\n",
    "        return True\n",
    "    if n % 2 == 0 or n % 3 == 0:\n",
    "        return False\n",
    "    i = 5\n",
    "    while i * i <= n:\n",
    "        if n % i == 0 or n % (i + 2) == 0:\n",
    "            return False\n",
    "        i += 6\n",
    "    return True\n",
    "\n",
    "primes = []\n",
    "num = 2\n",
    "while len(primes) < 50:\n",
    "    if is_prime(num):\n",
    "        primes.append(num)\n",
    "    num += 1\n",
    "\n",
    "sum_of_primes = sum(primes)\n",
    "print(f'{sum_of_primes=}')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40961b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the code execution results.\n",
    "# The following code iterates through the response and displays the execution result \n",
    "# and outcome by checking for part.code_execution_result in the response parts:\n",
    "\n",
    "for part in response.candidates[0].content.parts:\n",
    "    if part.code_execution_result:\n",
    "        display(Markdown(f\"`{part.code_execution_result.output}`\"))\n",
    "        print(\"\\nOutcome:\", part.code_execution_result.outcome)    \n",
    "\n",
    "'''\n",
    "Output:\n",
    "\n",
    "sum_of_primes=5117\n",
    "\n",
    "Outcome: Outcome.OUTCOME_OK\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d6dd83",
   "metadata": {},
   "source": [
    "### Task 4. Write a function to handle various parts in the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90030ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You don't want to have to repeat code blocks like those cells above that iterate through the function's response.\n",
    "# This is especially true if you consider that those blocks would be even longer if you also displayed \n",
    "# the text or inline data that the model can return.\n",
    "#\n",
    "# Instead, it can often be a good idea to define a function to handle the model's responses. \n",
    "# The following function will help you display:\n",
    "#  - text sent as part.text\n",
    "#  - generated images sent as inline data by checking for part.inline_data and then part.inline_data.mime_type to understand the file type and part.inline_data.data to receive the data itself\n",
    "#  - generated Python code and execution results by checking for part.executable_code and part.code_execution_result:\n",
    "    \n",
    "# Run the following code in a new cell to define the handle_response function:\n",
    "\n",
    "def handle_response(response):\n",
    "    for part in response.candidates[0].content.parts:\n",
    "        # For text responses\n",
    "        if part.text:\n",
    "            display(Markdown(part.text))\n",
    "\n",
    "        # For generated inline image responses\n",
    "        if part.inline_data:\n",
    "            if part.inline_data.mime_type.startswith(\"image\"):\n",
    "                Image(image_bytes = part.inline_data.data).show()            \n",
    "\n",
    "        # For executable code responses (code)\n",
    "        if part.executable_code:\n",
    "            print(part.executable_code.code)\n",
    "        \n",
    "        # For executable code responses (results)\n",
    "        if part.code_execution_result:\n",
    "            display(Markdown(f\"`{part.code_execution_result.output}`\"))\n",
    "            print(\"\\nOutcome:\\n\")\n",
    "            display(Markdown(part.code_execution_result.outcome))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761236eb",
   "metadata": {},
   "source": [
    "### Task 5. Use code execution in a chat session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d523453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this section, you will create a chat session with the Gemini model, enabling code execution. \n",
    "# You will then interact with the model one chat message at a time to generate time series data, \n",
    "# add a smoothed data series, and calculate descriptive statistics, displaying the generated code\n",
    "# and results for each step.\n",
    "\n",
    "# Use client.chats.create to create a chat session. \n",
    "# Pass in the code execution tool and a system_instruction that reinforces using the Tool at the appropriate times:\n",
    "\n",
    "code_execution_tool = Tool(code_execution=ToolCodeExecution())\n",
    "\n",
    "chat = client.chats.create(\n",
    "    model=\"gemini-2.0-flash-001\",\n",
    "    config=GenerateContentConfig(\n",
    "        tools=[code_execution_tool],\n",
    "        temperature=0,\n",
    "        system_instruction=\"Use the code execution Tool when asked to generate data, code or plots.\"\n",
    "    ),\n",
    ")    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bde32c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the following code in a cell to ask the model to create sample time series data with noise \n",
    "# and then output a sample of 10 data points:\n",
    "\n",
    "PROMPT = \"\"\"Create sample time series data of temperature vs. time in a test furnace.\n",
    "Add noise to the data. Output a sample of 10 data points from the time series data.\"\"\"\n",
    "\n",
    "response = chat.send_message(PROMPT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571d644f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the handle_response function to display results:\n",
    "handle_response(response)\n",
    "\n",
    "'''\n",
    "Output:\n",
    "\n",
    "Okay, I can create sample time series data of temperature vs. time in a test furnace and add noise to it. Here's how I'll approach this:\n",
    "\n",
    "Define Time Range: I'll define a time range for the experiment, say from 0 to 10 hours.\n",
    "Generate Time Points: I'll generate a series of time points within this range.\n",
    "Define Temperature Function: I'll define a function that represents the temperature profile of the furnace. This could be a simple linear increase, a more complex curve, or a combination of both.\n",
    "Calculate Temperature Values: I'll calculate the temperature values at each time point using the defined function.\n",
    "Add Noise: I'll add random noise to the temperature values to simulate real-world measurement errors.\n",
    "Output Sample: Finally, I'll output a sample of 10 data points from the generated time series data.\n",
    "Here's the Python code to do this:\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Define time range\n",
    "start_time = 0\n",
    "end_time = 10\n",
    "num_points = 100\n",
    "\n",
    "# Generate time points\n",
    "time = np.linspace(start_time, end_time, num_points)\n",
    "\n",
    "# Define temperature function (example: linear increase with a slight curve)\n",
    "def temperature_function(t):\n",
    "  return 20 + 5*t + 0.5*t**2\n",
    "\n",
    "# Calculate temperature values\n",
    "temperature = temperature_function(time)\n",
    "\n",
    "# Add noise\n",
    "noise_level = 5  # Adjust this to control the amount of noise\n",
    "noise = np.random.normal(0, noise_level, num_points)\n",
    "temperature_noisy = temperature + noise\n",
    "\n",
    "# Create a Pandas DataFrame for better presentation\n",
    "data = pd.DataFrame({'Time': time, 'Temperature': temperature, 'Temperature_Noisy': temperature_noisy})\n",
    "\n",
    "# Output a sample of 10 data points\n",
    "sample = data.sample(10)\n",
    "print(sample)\n",
    "\n",
    "Time Temperature Temperature_Noisy 64 6.464646 73.219059 73.770154 10 1.010101 25.560657 20.506180 9 0.909091 24.958678 22.358408 23 2.323232 34.314866 37.224912 77 7.777778 89.135802 94.490204 47 4.747475 55.006632 50.985786 94 9.494949 112.551780 103.657782 32 3.232323 41.385573 46.717436 8 0.808081 24.366901 23.027145 65 6.565657 74.382206 82.309670\n",
    "\n",
    "\n",
    "Outcome:\n",
    "\n",
    "OUTCOME_OK\n",
    "\n",
    "The code generated a time series of temperature data with added noise. The temperature increases over time, and the noise simulates real-world measurement variations. A sample of 10 data points, including time, original temperature, and noisy temperature, is printed. You can adjust the noise_level variable in the code to control the amount of noise added to the data.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b21445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now you can ask the model to add a smoothed data series to the time series data:\n",
    "\n",
    "PROMPT = \"\"\"Now add a data series that smooths the data using an appropriate method\"\"\"\n",
    "\n",
    "response = chat.send_message(PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9bcc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then display the generated Python code and execution results:\n",
    "\n",
    "handle_response(response)\n",
    "\n",
    "\n",
    "'''\n",
    "Output:\n",
    "\n",
    "Here's the updated Python code:\n",
    "\n",
    "```py\n",
    "import numpy as np import pandas as pd\n",
    "\n",
    "Time range (hours)\n",
    "time = np.arange(0, 10, 1)\n",
    "\n",
    "Base temperature profile (Celsius)\n",
    "temperature = np.zeros_like(time, dtype=float) for i, t in enumerate(time): if t < 3: temperature[i] = 50 + 50 * t # Linear heating elif t < 7: temperature[i] = 200 # Plateau else: temperature[i] = 200 - 50 * (t - 7) # Linear cooling\n",
    "\n",
    "Add noise\n",
    "noise = np.random.normal(0, 5, size=len(time)) # Gaussian noise with std dev 5 temperature += noise\n",
    "\n",
    "Create Pandas DataFrame\n",
    "df = pd.DataFrame({'Time (hours)': time, 'Temperature (Celsius)': temperature})\n",
    "\n",
    "Add smoothed temperature using moving average\n",
    "df['Smoothed Temperature (Celsius)'] = df['Temperature (Celsius)'].rolling(window=3, center=True).mean()\n",
    "\n",
    "Output sample\n",
    "print(df.sample(10))\n",
    "```\n",
    "\n",
    "Time (hours) Temperature (Celsius) Smoothed Temperature (Celsius) \n",
    "0 0 47.555003 NaN 3 3 207.019445 186.951229 6 6 \n",
    "198.235366 200.160161 9 9 103.570919 NaN 2 2 152.048137 155.950125 \n",
    "1 1 108.782793 102.795311 7 7 199.451562 184.338888 8 8 \n",
    "155.329736 152.784072 4 4 201.786105 203.866369 5 5 202.793556 200.938342\n",
    "\n",
    "Outcome:\n",
    "\n",
    "OUTCOME_OK\n",
    "\n",
    "Now the output includes a \"Smoothed Temperature (Celsius)\" column, \n",
    "which contains the moving average of the temperature data. \n",
    "\n",
    "Note that the first and last values in the smoothed column are NaN \n",
    "because the moving average with a window of 3 cannot be calculated for those points \n",
    "(due to lack of neighbors). \n",
    "\n",
    "Using center=True in the rolling function centers the window on the data point, \n",
    "which is generally preferred for smoothing.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e53da09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask the model to generate code for a plot to compare the data:\n",
    "\n",
    "PROMPT = \"\"\"Generate code to plot the noisy data and smoothed data.\"\"\"\n",
    "\n",
    "response = chat.send_message(PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfb8470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the results:\n",
    "\n",
    "handle_response(response)\n",
    "\n",
    "\n",
    "'''\n",
    "Output:\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define time range\n",
    "start_time = 0\n",
    "end_time = 10\n",
    "num_points = 100\n",
    "\n",
    "# Generate time points\n",
    "time = np.linspace(start_time, end_time, num_points)\n",
    "\n",
    "# Define temperature function (example: linear increase with a slight curve)\n",
    "def temperature_function(t):\n",
    "  return 20 + 5*t + 0.5*t**2\n",
    "\n",
    "# Calculate temperature values\n",
    "temperature = temperature_function(time)\n",
    "\n",
    "# Add noise\n",
    "noise_level = 5  # Adjust this to control the amount of noise\n",
    "noise = np.random.normal(0, noise_level, num_points)\n",
    "temperature_noisy = temperature + noise\n",
    "\n",
    "# Create a Pandas DataFrame for better presentation\n",
    "data = pd.DataFrame({'Time': time, 'Temperature': temperature, 'Temperature_Noisy': temperature_noisy})\n",
    "\n",
    "# Add a moving average to smooth the data\n",
    "window_size = 5  # Adjust this to control the smoothing level\n",
    "data['Temperature_Smoothed'] = data['Temperature_Noisy'].rolling(window=window_size).mean()\n",
    "\n",
    "# Handle NaN values that appear at the beginning due to rolling mean\n",
    "data['Temperature_Smoothed'] = data['Temperature_Smoothed'].fillna(method='bfill') # Backfill to fill NaN values\n",
    "\n",
    "# Plot the noisy and smoothed data\n",
    "plt.figure(figsize=(10, 6))  # Adjust figure size for better readability\n",
    "plt.plot(data['Time'], data['Temperature_Noisy'], label='Noisy Temperature', alpha=0.7)\n",
    "plt.plot(data['Time'], data['Temperature_Smoothed'], label='Smoothed Temperature', linewidth=2)\n",
    "plt.xlabel('Time (hours)')\n",
    "plt.ylabel('Temperature')\n",
    "plt.title('Test Furnace Temperature Data')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514ac7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, ask the model to generate descriptive statistics for the time series data and display the results:\n",
    "PROMPT = \"Now generate and output descriptive statistics on the time series data.\"\n",
    "\n",
    "response = chat.send_message(PROMPT)\n",
    "handle_response(response)\n",
    "\n",
    "'''\n",
    "Output:\n",
    "\n",
    "Here's the updated code:\n",
    "\n",
    "```py\n",
    "import numpy as np import pandas as pd\n",
    "\n",
    "Time range (hours)\n",
    "time = np.arange(0, 10, 1)\n",
    "\n",
    "Base temperature profile (Celsius)\n",
    "temperature = np.zeros_like(time, dtype=float) for i, t in enumerate(time): if t < 3: temperature[i] = 50 + 50 * t # Linear heating elif t < 7: temperature[i] = 200 # Plateau else: temperature[i] = 200 - 50 * (t - 7) # Linear cooling\n",
    "\n",
    "Add noise\n",
    "noise = np.random.normal(0, 5, size=len(time)) # Gaussian noise with std dev 5 temperature += noise\n",
    "\n",
    "Create Pandas DataFrame\n",
    "df = pd.DataFrame({'Time (hours)': time, 'Temperature (Celsius)': temperature})\n",
    "\n",
    "Add smoothed temperature using moving average\n",
    "window_size = 3 # Adjust window size as needed df['Smoothed Temperature'] = df['Temperature (Celsius)'].rolling(window=window_size, center=True).mean()\n",
    "\n",
    "Generate descriptive statistics\n",
    "descriptive_stats = df[['Temperature (Celsius)', 'Smoothed Temperature']].describe()\n",
    "\n",
    "Output descriptive statistics\n",
    "print(descriptive_stats)\n",
    "```\n",
    "\n",
    "Temperature (Celsius) Smoothed Temperature count 10.000000 8.000000 mean 155.563573 171.757223 std 55.277283 34.587456 min 51.157644 103.001673 25% 115.084961 152.208948 50% 174.050047 183.605867 75% 201.882207 199.511392 max 204.171309 202.472192\n",
    "\n",
    "Outcome:\n",
    "\n",
    "OUTCOME_OK\n",
    "\n",
    "The output shows the descriptive statistics for both the 'Temperature (Celsius)' and 'Smoothed Temperature' columns. These statistics include the count, mean, standard deviation, minimum, 25th percentile, 50th percentile (median), 75th percentile, and maximum values. The count is 8 for the smoothed temperature because the rolling average with center=True produces NaN values at the beginning and end of the series.\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
