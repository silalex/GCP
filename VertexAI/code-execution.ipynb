{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca131e67",
   "metadata": {},
   "source": [
    "# Code Execution with Gemini\n",
    "\n",
    "[Lab link](https://partner.cloudskillsboost.google/paths/2294/course_templates/1235/labs/527178)\n",
    "\n",
    "Note: this ipy-notebook was created step-by-spet according to the lab instructions (there is no a template file is ready to use)\n",
    "\n",
    "### Objective\n",
    "\n",
    "In this lab, you will learn how to generate and execute code using the Gemini API in Vertex AI and the Google Gen AI SDK for Python with the Gemini 2.0 Flash model.\n",
    "\n",
    "You will complete the following tasks:\n",
    " - Generate and run sample Python code from text prompts.\n",
    " - Explore data using code execution in multi-turn chats.\n",
    " - Use code execution in streaming sessions.\n",
    "\n",
    " ### Task 1. Initialize the Google Gen AI SDK in a Colab Enterprise notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e3ce61",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "# Install the Google Gen AI SDK and restart the kernel\n",
    "%pip install --upgrade --quiet google-\n",
    "\n",
    "# After the cell completes running, indicated by a checkmark to the left of the cell, \n",
    "# the new packages should be installed. To use them, restart the runtime by selecting Runtime \n",
    "# from the menu bar and clicking Restart Session. \n",
    "#\n",
    "# When asked to confirm, select Yes. The runtime will restart, indicated by clearing the green checkmark \n",
    "# and the integer next to the cell above representing the order in which the cells have run."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689e5a03",
   "metadata": {},
   "source": [
    "### Task 2. Initialize the Google Gen AI SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab5dc2d",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from IPython.display import HTML, Markdown, display\n",
    "from google import genai\n",
    "from google.genai.types import GenerateContentConfig, Tool, ToolCodeExecution, Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855161fb",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = os.environ.get(\"GOOGLE_CLOUD_PROJECT\")\n",
    "LOCATION = os.environ.get(\"GOOGLE_CLOUD_REGION\", \"us-central1\")\n",
    "\n",
    "client = genai.Client(vertexai=True, project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d90ff1",
   "metadata": {},
   "source": [
    "### Task 3. Generate and execute code with Gemini 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038f24f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the code execution tool you imported above:\n",
    "code_execution_tool = Tool(code_execution=ToolCodeExecution())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "182896fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a prompt to instruct the model to generate code. Note that the model decides \n",
    "# when to use tools such as code generation (as opposed to returning code as text, \n",
    "# for example), so your prompt is important to direct the model to do what you would like:\n",
    "\n",
    "PROMPT = \"\"\"\n",
    "What is the sum of the first 50 prime numbers?\n",
    "Generate and run code for the calculation.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ca2627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the following to send the prompt to the model. \n",
    "# Note that the code execution tool is passed to the request so the model can use it:\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash-001\",\n",
    "    contents=PROMPT,\n",
    "    config=GenerateContentConfig(\n",
    "        tools=[code_execution_tool],\n",
    "        temperature=0,\n",
    "    ),\n",
    ")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d794bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following code iterates through the response and displays any generated Python code\n",
    "# by checking for part.executable_code in the response parts:\n",
    "\n",
    "for part in response.candidates[0].content.parts:\n",
    "    if part.executable_code:\n",
    "        print(part.executable_code.code)\n",
    "\n",
    "\n",
    "'''\n",
    "Output:\n",
    "\n",
    "def is_prime(n):\n",
    "    if n <= 1:\n",
    "        return False\n",
    "    if n <= 3:\n",
    "        return True\n",
    "    if n % 2 == 0 or n % 3 == 0:\n",
    "        return False\n",
    "    i = 5\n",
    "    while i * i <= n:\n",
    "        if n % i == 0 or n % (i + 2) == 0:\n",
    "            return False\n",
    "        i += 6\n",
    "    return True\n",
    "\n",
    "primes = []\n",
    "num = 2\n",
    "while len(primes) < 50:\n",
    "    if is_prime(num):\n",
    "        primes.append(num)\n",
    "    num += 1\n",
    "\n",
    "sum_of_primes = sum(primes)\n",
    "print(f'{sum_of_primes=}')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40961b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the code execution results.\n",
    "# The following code iterates through the response and displays the execution result \n",
    "# and outcome by checking for part.code_execution_result in the response parts:\n",
    "\n",
    "for part in response.candidates[0].content.parts:\n",
    "    if part.code_execution_result:\n",
    "        display(Markdown(f\"`{part.code_execution_result.output}`\"))\n",
    "        print(\"\\nOutcome:\", part.code_execution_result.outcome)    \n",
    "\n",
    "'''\n",
    "Output:\n",
    "\n",
    "sum_of_primes=5117\n",
    "\n",
    "Outcome: Outcome.OUTCOME_OK\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d6dd83",
   "metadata": {},
   "source": [
    "### Task 4. Write a function to handle various parts in the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90030ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You don't want to have to repeat code blocks like those cells above that iterate through the function's response.\n",
    "# This is especially true if you consider that those blocks would be even longer if you also displayed \n",
    "# the text or inline data that the model can return.\n",
    "#\n",
    "# Instead, it can often be a good idea to define a function to handle the model's responses. \n",
    "# The following function will help you display:\n",
    "#  - text sent as part.text\n",
    "#  - generated images sent as inline data by checking for part.inline_data and then part.inline_data.mime_type to understand the file type and part.inline_data.data to receive the data itself\n",
    "#  - generated Python code and execution results by checking for part.executable_code and part.code_execution_result:\n",
    "    \n",
    "# Run the following code in a new cell to define the handle_response function:\n",
    "\n",
    "def handle_response(response):\n",
    "    for part in response.candidates[0].content.parts:\n",
    "        # For text responses\n",
    "        if part.text:\n",
    "            display(Markdown(part.text))\n",
    "\n",
    "        # For generated inline image responses\n",
    "        if part.inline_data:\n",
    "            if part.inline_data.mime_type.startswith(\"image\"):\n",
    "                Image(image_bytes = part.inline_data.data).show()            \n",
    "\n",
    "        # For executable code responses (code)\n",
    "        if part.executable_code:\n",
    "            print(part.executable_code.code)\n",
    "        \n",
    "        # For executable code responses (results)\n",
    "        if part.code_execution_result:\n",
    "            display(Markdown(f\"`{part.code_execution_result.output}`\"))\n",
    "            print(\"\\nOutcome:\\n\")\n",
    "            display(Markdown(part.code_execution_result.outcome))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
